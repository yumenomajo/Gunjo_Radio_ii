<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><div id="myscoll"></div><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>抽样技术大总结 | 群青广播II📡</title><meta name="keywords" content="抽样技术,统计"><meta name="author" content="yumenomajo🧙‍"><meta name="copyright" content="yumenomajo🧙‍"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="简单随机抽样 一、抽样方法与特点 定义： 简单随机抽样 从含有 N 个单元的有限总体中抽取 n 个单元组成样本，如果抽样是放回的，称为有放回简单随机抽样； 如果抽样是无放回的，称为无放回简单随机抽样。 无放回简单随机抽样有更高的效率，实践中常采用。  性质1  简单随机抽样下，每个样本被抽中的概率相等。 性质2 简单随机抽样下，总体各单元入样概率相等，最终包含概率也相等。  抽样方法： 抽签法 随">
<meta property="og:type" content="article">
<meta property="og:title" content="抽样技术大总结">
<meta property="og:url" content="https://gunjo-radio-ii.cc/posts/97773c8f.html">
<meta property="og:site_name" content="群青广播II📡">
<meta property="og:description" content="简单随机抽样 一、抽样方法与特点 定义： 简单随机抽样 从含有 N 个单元的有限总体中抽取 n 个单元组成样本，如果抽样是放回的，称为有放回简单随机抽样； 如果抽样是无放回的，称为无放回简单随机抽样。 无放回简单随机抽样有更高的效率，实践中常采用。  性质1  简单随机抽样下，每个样本被抽中的概率相等。 性质2 简单随机抽样下，总体各单元入样概率相等，最终包含概率也相等。  抽样方法： 抽签法 随">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gunjo-radio-ii.cc/images/cover.jpg">
<meta property="article:published_time" content="2024-12-13T01:32:53.000Z">
<meta property="article:modified_time" content="2025-02-01T15:10:58.861Z">
<meta property="article:author" content="yumenomajo🧙‍">
<meta property="article:tag" content="抽样技术">
<meta property="article:tag" content="统计">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gunjo-radio-ii.cc/images/cover.jpg"><link rel="shortcut icon" href="/images/tang%20kotori.png"><link rel="canonical" href="https://gunjo-radio-ii.cc/posts/97773c8f"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '抽样技术大总结',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-01 23:10:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><style id="themeColor"></style><style id="rightSide"></style><style id="transPercent"></style><style id="blurNum"></style><style id="settingStyle"></style><span id="fps"></span><style id="defineBg"></style><style id="menu_shadow"></style><div class="aplayer no-destroy" data-id="9387575714" data-volume="0.4" data-server="netease" data-type="playlist" data-fixed="true"  data-autoplay="false" data-lrcType="-1"> </div><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="群青广播II📡" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="wizard-scene"><div class="wizard-objects"><div class="wizard-square"></div><div class="wizard-circle"></div><div class="wizard-triangle"></div></div><div class="wizard"><div class="wizard-body"></div><div class="wizard-right-arm"><div class="wizard-right-hand"></div></div><div class="wizard-left-arm"><div class="wizard-left-hand"></div></div><div class="wizard-head"><div class="wizard-beard"></div><div class="wizard-face"><div class="wizard-adds"></div></div><div class="wizard-hat"><div class="wizard-hat-of-the-hat"></div><div class="wizard-four-point-star --first"></div><div class="wizard-four-point-star --second"></div><div class="wizard-four-point-star --third"></div></div></div></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/avatar.jpg" onerror="onerror=null;src='/assets/r1.jpg'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan"></use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane"></use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">群青广播II📡</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan"></use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane"></use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="search faa-parent animated-hover" title="检索站内任何你想要的信息"><svg class="faa-tada icon" style="height:24px;width:24px;fill:currentColor;position:relative;top:6px" aria-hidden="true"><use xlink:href="#icon-valentine_-search-love-find-heart"></use></svg><span> 搜索</span></a></div><a class="meihua faa-parent animated-hover" onclick="toggleWinbox()" title="美化设置-自定义你的风格" id="meihua-button"><svg class="faa-tada icon" style="height:26px;width:26px;fill:currentColor;position:relative;top:8px" aria-hidden="true"><use xlink:href="#icon-tupian1"></use></svg></a><a class="sun_moon faa-parent animated-hover" onclick="switchNightMode()" title="浅色和深色模式转换" id="nightmode-button"><svg class="faa-tada" style="height:25px;width:25px;fill:currentColor;position:relative;top:7px" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon">       </use></svg></a><div id="toggle-menu"><a><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-info"><h1 class="post-title">抽样技术大总结<a class="post-edit-link" href="null_posts/sample_survey/整理.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于 </span><time class="post-meta-date-created" datetime="2024-12-13T01:32:53.000Z" title="发表于 2024-12-13 09:32:53">2024-12-13</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-01T15:10:58.861Z" title="更新于 2025-02-01 23:10:58">2025-02-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E6%8A%BD%E6%A0%B7%E8%B0%83%E6%9F%A5/">抽样调查</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">1.4w</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>58分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="抽样技术大总结"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>简单随机抽样</h1>
<h2 id="一、抽样方法与特点">一、抽样方法与特点</h2>
<h3 id="定义：">定义：</h3>
<p><strong>简单随机抽样</strong></p>
<p>从含有 N 个单元的有限总体中抽取 n 个单元组成样本，如果抽样是放回的，称为<strong>有放回简单随机抽样</strong>；</p>
<p>如果抽样是无放回的，称为<strong>无放回简单随机抽样</strong>。</p>
<p><strong>无放回简单随机抽样</strong>有更高的效率，实践中常采用。</p>
<hr>
<p><strong>性质1</strong>  简单随机抽样下，每个样本被抽中的概率相等。</p>
<p><strong>性质2</strong> 简单随机抽样下，总体各单元入样概率相等，最终包含概率也相等。</p>
<hr>
<p>抽样方法：<br>
抽签法<br>
随机数表<br>
计算机抽样程序(目前常用) 等</p>
<h2 id="二、估计量与估计量性质">二、估计量与估计量性质</h2>
<h3 id="三个常用估计量：">三个常用估计量：</h3>
<ul>
<li>
<p>均值估计：$\hat{\bar{Y}}=\bar{y}=\sum_{i=1}^ny_i$</p>
</li>
<li>
<p>总量估计：$\hat{Y}=N\bar{y}$</p>
</li>
<li>
<p>比例估计:$\hat{P}=p=\frac{a}{n}$</p>
</li>
</ul>
<p>对应性质（期望和方差）：</p>
<blockquote>
<h4 id="均值估计：">均值估计：</h4>
<ol>
<li>期望${E}(\hat{\bar{Y}})=\bar{Y}$ 无偏估计</li>
<li>方差${V}(\hat{\bar{Y}})=\frac{1-f}{n}S^2$</li>
</ol>
<blockquote>
<p>实际工作中不知道真正的$S^2$，故用$s^2$来估计$S^2$,进而评估估计量的方差。</p>
<p>估计量方差的无偏估计[个人理解估计量的估计换小写]:${v}(\hat{\bar{Y}})=\frac{1-f}{n}s^2$</p>
</blockquote>
</blockquote>
<blockquote>
<h4 id="总量估计：">总量估计：</h4>
<ol>
<li><strong>期望</strong><br>
$E(\hat{Y})=N\bar{Y}$<br>
无偏估计。</li>
<li><strong>方差</strong><br>
$V(\hat{Y})=N^2\cdot\frac{1-f}{n}S^2$<br>
用样本方差$s^2$代替总体的$S^2$来估计。</li>
</ol>
<blockquote>
<p>估计量方差的无偏估计：<br>
$v(\hat{Y})=N^2\cdot\frac{1-f}{n}s^2$</p>
</blockquote>
</blockquote>
<blockquote>
<h4 id="比例估计：">比例估计：</h4>
<ol>
<li><strong>期望</strong><br>
$E(\hat{P})=P$<br>
无偏估计。</li>
<li><strong>方差</strong><br>
$$V(\hat{P}) = \frac{1-f}{n}S_p^2=\frac{(1-f) N P(1-P)}{n (N-1)} = \frac{(N-n) P(1-P)}{(N-1) n}$$</li>
</ol>
<p>由于$N$和$P$未知，本质上是$S_p$未知，在实际工作中用样本比例$s_p^2=\frac{np(1-p)}{n-1}$来估计总体比例$S_p^2=\frac{NP(1-P)}{N-1}$。<br>
估计量方差的无偏估计:<br>
$$V(\hat{P}) = \frac{1-f}{n}s_p^2=\frac{(1-f) n p(1-p)}{n (n-1)} = \frac{(1-f) p(1-p)}{(n-1) }$$</p>
</blockquote>
<hr>
<p>补充：放回简单随机抽样：</p>
<h3 id="放回简单随机抽样中的估计量及其性质">放回简单随机抽样中的估计量及其性质</h3>
<p>设$y_1, y_2, \cdots, y_n$为样本量为$n$的放回简单随机样本，$y_i$表示第$i$次抽取得到的标志值。</p>
<p>由于放回抽样中每次抽取时总体结构不变，因此$y_i$相互独立并服从相同分布，总体中每个单位$Y_j(j=1,2,\cdots,N)$被抽取的概率均为$\frac{1}{N}$。</p>
<blockquote>
<h4 id="均值估计：-2">均值估计：</h4>
<ol>
<li>
<p><strong>期望</strong><br>
样本均值$\bar{y}$作为总体均值$\bar{Y}$的估计，具有以下性质：<br>
$$E(\bar{y})=\bar{Y}$$<br>
无偏估计。</p>
</li>
<li>
<p><strong>方差</strong><br>
样本均值的方差为：<br>
$$V(\bar{y})=\frac{1}{n}\sigma^2$$<br>
其中$\sigma^2=\frac{1}{N}\sum_{j=1}^N(Y_j-\bar{Y})^2$为总体方差。</p>
</li>
</ol>
</blockquote>
<blockquote>
<h4 id="总量估计：-2">总量估计：</h4>
<ol>
<li>
<p><strong>期望</strong><br>
总量估计为$\hat{Y}=N\bar{y}$，其期望为：<br>
$$E(\hat{Y})=N\bar{Y}$$<br>
无偏估计。</p>
</li>
<li>
<p><strong>方差</strong><br>
总量估计的方差为：<br>
$$V(\hat{Y})=N^2\cdot\frac{1}{n}\sigma^2$$</p>
</li>
</ol>
</blockquote>
<hr>
<p>实际上，类似于上面的估计量估计，这里也可以用$s^2$估计$\sigma^2$。</p>
<p>对比：</p>
<ol>
<li>放回简单随机抽样：样本方差$s^2$均为总体方差$\sigma^2$的无偏估计</li>
<li>不放回简单随机抽样：样本方差$s^2$均为总体方差$S^2$的无偏估计</li>
</ol>
<p>具体证明详见课本P32。</p>
<h3 id="放回抽样与不放回抽样的比较">放回抽样与不放回抽样的比较</h3>
<ol>
<li><strong>设计效应（Design Effect, deff）</strong><br>
不放回抽样的估计量方差为$\frac{1-f}{n}S^2$，而放回抽样的估计量方差为$\frac{1}{n}\sigma^2$，二者的倍数关系为：<br>
$$\text{deff}=\frac{\frac{1}{n}\sigma^2}{\frac{1-f}{n}S^2}=\frac{N-1}{N-n}&gt;1$$<br>
其中$f=\frac{n}{N}$为抽样率。显然，与不放回简单随机抽样相比，放回简单随机抽样的设计效应应满足$\text{deff}&gt;1$。</li>
<li>精度原因探究看P32。</li>
</ol>
<hr>
<h2 id="三、样本量的确定（广义讨论）">三、样本量的确定（广义讨论）</h2>
<p>影响样本量的因素：<strong>费用</strong>，<strong>估计精度</strong>，以及<strong>估计量本身的性质（波动程度）</strong>。</p>
<p>高精度往往伴随着高费用，因此我们必须在高精度和低费用之间抉择。<br>
客观上，合适的样本量受到估计量本身性质约束。</p>
<h3 id="1-费用：">1. 费用：</h3>
<p>费用函数          $C=c_0+c_1 n$<br>
$$总费用 = 固定费用  +  可变费用$$<br>
𝐶一定时，可得到样本量上限<br>
$$n=(C-c_0)/c_1$$</p>
<hr>
<h3 id="2-估计精度：">2.估计精度：</h3>
<h4 id="A-精度要求与样本量的关系：">A. 精度要求与样本量的关系：</h4>
<blockquote>
<p>自己的思考：<strong>误差</strong>、<strong>置信水平</strong>、<strong>估计量方差</strong>（一般由样本量决定）三位一体，知道其中二者可确定第三者。</p>
</blockquote>
<h4 id="B-精度-误差和置信水平讨论：">B. 精度-误差和置信水平讨论：</h4>
<p>精度关键在于两个参数：<br>
<strong>误差</strong> <strong>置信水平</strong></p>
<p>在知道参数估计量方差的情况下，<strong>误差</strong>和<strong>置信水平</strong>可以相互确定。</p>
<p>对于估计参数$\theta$的调查精度要求，通常使用<strong>绝对误差</strong>$d$或<strong>相对误差</strong>$r$表示，即在置信水平$1-\alpha$下，保证估计量$\hat{\theta}$与待估参数$\theta$的误差满足以下关系：</p>
<h3 id="绝对误差表示：">绝对误差表示：</h3>
<p>$$<br>
P(|\hat{\theta} - \theta| \leq d) = 1-\alpha \tag{2.25}<br>
$$</p>
<h3 id="相对误差表示：">相对误差表示：</h3>
<p>$$<br>
P\left(\left|\frac{\hat{\theta} - \theta}{\theta}\right| \leq r\right) = 1-\alpha \tag{2.26}<br>
$$</p>
<h4 id="C-估计量方差与精度（误差和置信水平）关系">C. 估计量方差与精度（误差和置信水平）关系</h4>
<p>当样本量$n$较大（通常$n &gt; 30$）时，根据中心极限定理，估计量$\hat{\theta}$近似服从正态分布：<br>
$$<br>
\hat{\theta} \sim N(\theta, V(\hat{\theta}))<br>
$$<br>
在置信水平$1-\alpha$下，有：<br>
$$<br>
P\left(\frac{|\hat{\theta} - \theta|}{\sqrt{V(\hat{\theta})}} \leq u\right) = 1-\alpha \tag{2.27}<br>
$$<br>
其中，$u$是标准正态分布的双侧$\alpha$分位数。当$\alpha=0.05$时，$u=1.96$。</p>
<p>因此，<strong>绝对误差</strong>$d$和<strong>相对误差</strong>$r$可表示为：</p>
<ul>
<li><strong>绝对误差</strong>：<br>
$$<br>
d = u\sqrt{V(\hat{\theta})} \tag{2.28}<br>
$$</li>
<li><strong>相对误差</strong>：<br>
$$<br>
r = \frac{u\sqrt{V(\hat{\theta})}}{\theta} \tag{2.29}<br>
$$</li>
</ul>
<hr>
<h4 id="3，-求得合适样本量">3， 求得合适样本量</h4>
<p>根据调查精度对绝对误差$d$或相对误差$r$的要求以及设定置信水平$1-\alpha$，由公式$(2.28)$和$(2.29)$可以确定抽样方差$V(\hat{\theta})$，进而计算所需的样本量$n$。</p>
<p>对于简单随机抽样，抽样方差$V(\hat{\theta})$通常只与总体特征和样本量有关。总特征确定时，样本方差是样本量的函数。通过调节相关关系，可以解出所需要的样本量$n$。</p>
<hr>
<h2 id="四、样本量的确定（简单随机抽样）">四、样本量的确定（简单随机抽样）</h2>
<h3 id="均值估计：-3">均值估计：</h3>
<p>已知绝对误差d:<br>
$$n=\frac{Nu^2 S^2}{Nd^2+u^2 S^2}$$</p>
<p>已知绝对误差r:<br>
$$n=\frac{Nu^2 S^2}{Nr^2 \bar{Y}^2+u^2 S^2 }$$</p>
<h3 id="比例估计：-2">比例估计：</h3>
<p>$$<br>
n = \frac{\frac{u^2 P(1-P)}{d^2}}{1 + \frac{1}{N} \left( \frac{u^2 P(1-P)}{d^2} - 1 \right)}<br>
$$</p>
<hr>
<h2 id=""></h2>
<h1>分层抽样</h1>
<h2 id="一、抽样方法与特点-2">一、抽样方法与特点</h2>
<ul>
<li>利用辅助信息,在抽样之前将总体的N个单元划分为互不重叠的L个层,每一层包含的单元数分别为$N_1,N_2,…N_L$，且$N=N_1+N_2+⋯N_L$。随后抽样在每个层中独立地进行，分别从各个层中抽取容量为$𝑛_1,𝑛_2,…𝑛_L$的样本，得到容量为$𝑛(𝑛=𝑛_1+𝑛_2+⋯𝑛_𝑙)$的样本称为分层样本。</li>
<li>分层抽样特征:</li>
</ul>
<ol>
<li>实现样本结构与总体结构一致，提高估计效率；</li>
<li>在各层中可以采用不同概率抽样方法；</li>
<li>可以对各层的参数进行估计,增加分析内容的层次 。</li>
</ol>
<p>应用条件：各层差异较大，有进行分层的辅助信息。</p>
<ul>
<li>若每层中的抽样都是简单随机抽样，那么分层抽样就称为<strong>分层随机抽样</strong>，所得样本称为分层随机样本。</li>
</ul>
<hr>
<h2 id="二、估计量与估计量性质-2">二、估计量与估计量性质</h2>
<h3 id="三个常用估计量：-2">三个常用估计量：</h3>
<h4 id="均值估计：-4">均值估计：</h4>
<p>$\hat{\bar{Y_{st}}}=\sum_{h=1}^L W_h \hat{\bar{Y}<em>h}=\frac{1}{N}\sum</em>{h=1}^L N_h \hat{\bar{Y}_h}$</p>
<p>对于分层随机抽样：<br>
${\bar{y}<em>{st}}=\sum</em>{h=1}^L W_h \hat{\bar{y}<em>h}=\frac{1}{N}\sum</em>{h=1}^L N_h \hat{\bar{y}_h}$</p>
<h4 id="总量估计：-3">总量估计：</h4>
<p>$\hat{Y}<em>{st} = N \hat{\bar{Y}}</em>{st} = \sum_{h=1}^L \hat{Y}<em>h$<br>
对于分层随机抽样：<br>
$y</em>{st} = N \bar{y}<em>{st} = \sum</em>{h=1}^L y_h$</p>
<h4 id="比例估计：-3">比例估计：</h4>
<p>$\hat{P}=p_{st}=\sum_{h=1}^L W_h p_h$</p>
<h4 id="特征数量估计：">特征数量估计：</h4>
<p>$\hat{A} = N\hat{P} = \sum_{h=1}^L N_h p_h$</p>
<hr>
<h3 id="对应性质（期望和方差）：">对应性质（期望和方差）：</h3>
<h4 id="均值估计：-5">均值估计：</h4>
<ul>
<li><strong>性质 1</strong>：<strong>一般分层抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong></li>
</ul>
<p>若$E（\hat{\overline{Y}}_h）=\bar{Y}_h$（$h=1, 2, \cdots, L$）</p>
<p>则$E（\hat{\overline{Y}}<em>{st}）=\bar{Y}$的无偏估计。<br>
<strong>总体均值估计量方差</strong>：<br>
$${V}(\hat{\bar{Y}}</em>{st}) = \sum_{h=1}^L {W_h^2} V(\hat{\bar{Y}}_h)$$</p>
<ul>
<li>
<p><strong>性质 2</strong>：<strong>分层随机抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
$E（{\overline{y}}<em>{st}）=\bar{Y}$<br>
<strong>总体均值估计量方差</strong>：<br>
$${V}({\bar{y}}</em>{st}) = \sum_{h=1}^L {W_h^2} V({\bar{y}}<em>h)=\sum</em>{h=1}^L {W_h^2} \frac{1-f_h}{n}S_h^2$$</p>
</li>
<li>
<p><strong>性质 3</strong>：<strong>分层随机抽样</strong>的<strong>方差无偏估计</strong><br>
用$s_h^2$估计$S_h^2$即可：<br>
<strong>总体均值估计量方差</strong>：<br>
$${v}({\bar{y}}<em>{st}) = \sum</em>{h=1}^L {W_h^2} v({\bar{y}}<em>h)=\sum</em>{h=1}^L {W_h^2} \frac{1-f_h}{n}s_h^2$$</p>
</li>
</ul>
<hr>
<h4 id="总量估计：-4">总量估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>一般分层抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
若$E(\hat{\overline{Y}}<em>h) = \bar{Y}<em>h$（$h = 1, 2, \cdots, L$）<br>
则总体总量的估计为：  $E(\hat{Y}</em>{st}) = N\hat{\bar{Y}}</em>{st} = N\bar{Y}$<br>
<strong>总体总量估计量方差</strong>:<br>
$$V(\hat{Y}<em>{st}) = N^2 V(\hat{\bar{Y}}</em>{st}) = N^2 \sum_{h=1}^L W_h^2 V(\hat{\bar{Y}}<em>h)=\sum</em>{h=1}^L N_h^2 V(\hat{\bar{Y}}_h)$$</p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>分层随机抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
分层随机抽样下：  $E({y}<em>{st}) = {Y}$<br>
<strong>总体总量估计量方差</strong>：<br>
$$<br>
V({y}</em>{st}) = N^2 \sum_{h=1}^L W_h^2 V(\bar{y}<em>h) = N^2 \sum</em>{h=1}^L W_h^2 \frac{1-f_h}{n_h} S_h^2=  \sum_{h=1}^L N_h^2 \frac{1-f_h}{n_h} S_h^2<br>
$$</p>
</li>
<li>
<p><strong>性质 3</strong>：<strong>分层随机抽样</strong>的<strong>方差无偏估计</strong><br>
用$s_h^2$估计$S_h^2$，则总体总量估计量的方差无偏估计为：<br>
$$<br>
v({y}<em>{st}) = N^2 \sum</em>{h=1}^L W_h^2 v(\bar{y}<em>h) = N^2 \sum</em>{h=1}^L W_h^2 \frac{1-f_h}{n_h} s_h^2=  \sum_{h=1}^L N_h^2 \frac{1-f_h}{n_h} s_h^2<br>
$$</p>
</li>
</ul>
<h4 id="比例估计：-4">比例估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>一般分层抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
若$E(p_h)=P_h$<br>
则$E(p_{st})=P$<br>
比例估计的方差为：<br>
$$<br>
V(\hat{P}) = V({p_{st}}) =\sum_{h=1}^L W_h^2 V(p_h)<br>
$$</p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>分层随机抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
$E(p_{st})=P$<br>
<strong>比例估计的方差</strong>为：<br>
$$<br>
V(\hat{P})=V(p_{st}) = \sum_{h=1}^L W_h^2 V(p_h)=\sum_{h=1}^L W_h^2 \frac{1-f_h}{n_h} S_{p_h}^2=\sum_{h=1}^L W_h^2 \frac{1-f_h}{n_h} \frac{N_h P_h Q_h}{(N_h-1)}=\sum_{h=1}^L W_h^2 \frac{N_h - n_h}{N_h - 1} \frac{P_h Q_h}{n_h}<br>
$$<br>
$$<br>
\approx\sum_{h=1}^L W_h^2 \frac{N_h - n_h}{N_h } \frac{P_h Q_h}{n_h}=\sum_{h=1}^L W_h^2 \frac{1 - f_h}{n_h} P_h Q_h<br>
$$</p>
</li>
<li>
<p><strong>性质 3</strong>：分层随机抽样的<strong>方差</strong>无偏估计</p>
</li>
</ul>
<p><strong>比例估计方差的无偏估计</strong>为：<br>
$$<br>
v(\hat{P})=v(p_{st}) = \sum_{h=1}^L W_h^2 v(p_h)=\sum_{h=1}^L W_h^2 \frac{1-f_h}{n_h} s_{p_h}^2=\sum_{h=1}^L W_h^2 \frac{1-f_h}{n_h} \frac{n_h p_h q_h}{(n_h-1)}=\sum_{h=1}^L W_h^2 (1-f_h) \frac{p_h q_h}{n_h-1}<br>
$$</p>
<h4 id="特征数量估计">特征数量估计</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>一般分层抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
若$E（p_h）=P_h$<br>
则$E（\hat{A}）=A$<br>
其方差为：<br>
$$<br>
V(\hat{A}) = \sum_{h=1}^L N_h^2 V(p_h)<br>
$$</p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>分层随机抽样</strong>的<strong>无偏估计</strong>和<strong>方差</strong><br>
$E（\hat{A}）=A$<br>
其方差为：<br>
$$<br>
V(\hat{A}<em>{st}) = \sum</em>{h=1}^L N_h^2 \frac{N_h - n_h}{N_h - 1} \frac{P_h Q_h}{n_h}<br>
$$</p>
</li>
</ul>
<p>$$<br>
\approx \sum_{h=1}^L N_h^2 (1-f_h) \frac{P_h Q_h}{n_h}<br>
$$</p>
<ul>
<li><strong>性质 3</strong>：<strong>分层随机抽样</strong>的<strong>方差无偏估计</strong><br>
在实际工作中用样本比例$s_{p_h}^2=\frac{np(1-p)}{n-1}$来估计总体比例$S_{p_h}^2=\frac{NP(1-P)}{N-1}$。<br>
<strong>特征数量估计的方差无偏估计</strong>为：<br>
$$<br>
v(\hat{A}<em>{st}) = \sum</em>{h=1}^L N_h^2 (1-f_h) \frac{p_h q_h}{n_h-1}=\sum_{h=1}^L  N_h(N_h-n_h) \frac{p_h q_h}{n_h-1}<br>
$$</li>
</ul>
<h2 id="三、-样本量在各层的分配">三、 样本量在各层的分配</h2>
<h3 id="1-比例分配">1. 比例分配</h3>
<p>比例分配指的是按各层单元数占总单元数的比例，也就是按各层的层权进行分配。此时：</p>
<p>$$<br>
\frac{n_h}{n} = \frac{N_h}{N} = W_h \text{ 或 } f_h = \frac{n_h}{N_h} = \frac{n}{N} = f<br>
\tag{3.19}<br>
$$</p>
<p>对于分层随机抽样，总体均值 $\overline{Y}$ 的估计为：</p>
<p>$$<br>
\hat{\overline{Y}} = \overline{y}<em>{\text{prop}} = \sum</em>{h=1}^{L} W_h \overline{y}<em>h = \sum</em>{h=1}^{L} \frac{N_h}{N} \overline{y}<em>h = \sum</em>{h=1}^{L} \frac{n_h}{n} \sum_{i=1}^{n_h} \frac{y_{hi}}{n_h} = \frac{1}{n} \sum_{h=1}^{L} \sum_{i=1}^{n_h} y_{hi} = \frac{1}{n} \sum_{i=1}^{n} y_i = \overline{y}<br>
\tag{3.20}<br>
$$</p>
<p>其中，下标 <code>prop</code> 即 proportional（按比例）的缩写。</p>
<p>总体比例 $P$ 的估计为：</p>
<p>$$<br>
\hat{P}=p_{\text{prop}} = p = \frac{1}{n} \sum_{h=1}^{L} a_h<br>
\tag{3.21}<br>
$$</p>
<p>这是因为总体中的任意一个单元，不管它在哪一层，都以同样的概率入样。因此按比例分配的分层随机抽样，估计量的形式特别简单。这种样本也称为自加权的样本。</p>
<p>$\overline{y}_{\text{prop}}$ 的方差为：</p>
<p>$$<br>
V(\overline{y}<em>{\text{prop}}) = \sum</em>{h=1}^{L} W_h^2 V(\overline{y}<em>h) = \sum</em>{h=1}^{L} W_h \frac{n_h}{n} \frac{1-f_h}{n_h} S_h^2 = \frac{1-f}{n} \sum_{h=1}^{L} W_h S_h^2<br>
\tag{3.22}<br>
$$</p>
<p>$p_{\text{prop}}$ 的方差为：</p>
<p>$$<br>
V(p_{\text{prop}}) = \frac{1-f}{Nn} \sum_{h=1}^{L} \frac{N_h^2 P_h Q_h}{N_h-1} \approx \frac{1-f}{n} \sum_{h=1}^{L} W_h P_h Q_h<br>
\tag{3.23}<br>
$$</p>
<hr>
<h3 id="2-最优分配">2. 最优分配</h3>
<p>分层随机抽样，将样本量分配到各层，</p>
<p>条件：<span style="color:yellow">在总费用给定</span >，目标：<span style="color:red">估计量的方差达到最小</span ></p>
<p>条件：<span style="color:yellow">估计量方差给定</span >，目标：<span style="color:red">总费用最少</p>
<p>能满足这个条件的样本量分配就是<span style="color:purple">最优分配。</p>
<p>如果我们考虑简单线性费用函数，总费用为：</p>
<p>$$<br>
C = c_0 + \sum_{h=1}^{L} c_h n_h,<br>
\tag{3.24}<br>
$$</p>
<p>则此时的最优分配是：</p>
<p>$$<br>
\frac{n_h}{n} = \frac{\frac{W_h S_h}{\sqrt{c_h}}}{\sum_{h=1}^{L} \frac{W_h S_h}{\sqrt{c_h}}} = \frac{\frac{N_h S_h}{\sqrt{c_h}}}{\sum_{h=1}^{L} \frac{N_h S_h}{\sqrt{c_h}}}, \quad h = 1, 2, \dots, L.<br>
\tag{3.25}<br>
$$</p>
<p>由公式 (3.25) 可以看出，如果某一层单元数较多、内部差异较大、费用比较省，则对这一层的样本量要多分配一些。</p>
<hr>
<h3 id="3-奈曼分配">3. 奈曼分配</h3>
<p>对于分层随机抽样，作为特例，如果<strong>每层抽样的费用相同</strong>，即 $c_h = c$ 时，最优分配可简化为</p>
<p>$$<br>
\frac{n_h}{n} =  \frac{W_h S_h}{\sum_{h=1}^{L} W_h S_h} = \frac{N_h S_h}{\sum_{h=1}^{L} N_h S_h}, \quad h = 1, 2, \dots, L.<br>
\tag{3.26}<br>
$$</p>
<p>这种分配称为奈曼（Neyman）分配。这时，$V(\overline{y}_{st})$ 达到最小：</p>
<p>$$<br>
V_{\min}(\overline{y}<em>{st}) = \frac{1}{n} \left( \sum</em>{h=1}^{L} W_h S_h \right)^2 - \frac{1}{N} \sum_{h=1}^{L} W_h S_h^2.<br>
\tag{3.27}<br>
$$</p>
<hr>
<h2 id="四、总样本量的确定-关键在于理解n和V的负相关关系">四、总样本量的确定[关键在于理解n和V的负相关关系]</h2>
<h3 id="1-分层抽样样本量确定一般公式">1. 分层抽样样本量确定一般公式</h3>
<p>令 $n_h = n w_h$，其中 $w_h$ 已经选定，于是当方差 $V$ 给定时，</p>
<p>$$<br>
V = \sum_{h=1}^{L} W_h^2 \frac{1 - f_h}{n_h} S_h^2 = \sum_{h=1}^{L} \frac{W_h^2 S_h^2}{n_h} - \sum_{h=1}^{L} \frac{W_h^2 S_h^2}{N_h}<br>
$$</p>
<p>进一步化简得</p>
<p>$$<br>
V = \frac{1}{n} \sum_{h=1}^{L} \frac{W_h^2 S_h^2}{w_h} - \frac{1}{N} \sum_{h=1}^{L} W_h S_h^2<br>
$$</p>
<p>得到确定样本量的一般公式为</p>
<p>$$<br>
n = \frac{\sum_{h=1}^{L} \frac{W_h^2 S_h^2}{w_h}}{V + \frac{1}{N} \sum_{h=1}^{L} W_h S_h^2}.<br>
\tag{3.29}<br>
$$</p>
<hr>
<h3 id="2-不同应用场合">2. 不同应用场合</h3>
<p><span style="color:yellow">估计量的精度</span>取决于<span style="color:orange">每层样本量的大小</span></p>
<p>因此:</p>
<p><span style="color:blue">在总样本量给定的情况下</span>，<span style="color:orange">对于不同的样本量分配形式</span>，<span style="color:yellow">精度也不同</span>。</p>
<p><span style="color:blue">在同一精度要求下，<span style="color:orange">对于不同的样本量分配形式，<span style="color:yellow">计算得到的总样本量也有差异</span></span></span>。</p>
<p>因此:</p>
<p>目标：<span style="color:red">确定总样本量</span> 要求：<span style="color:blue">先确定样本量的分配形式</span></p>
<p><span style="color:red">个人的理解：总样本量（n）、分配方式</span>$w_h$<span style="color:red">、精度 三位一体。</span></p>
<p>如果估计精度是以误差限制的形式给出，则</p>
<p>$$<br>
V = \left( \frac{d}{u} \right)^2 = \left( \frac{r \overline{Y}}{u} \right)^2<br>
$$</p>
<p>其中，$ d $ 为绝对误差限制；$ r $ 为相对误差限制；$ u $ 为标准正态分布的双侧 $ \alpha $ 分位数；$ \overline{Y} $ 为总体均值。这样，(3.29) 式也可以表示为：</p>
<p>$$<br>
n = \frac{\sum_{h=1}^{L} \frac{W_h^2 S_h^2}{w_h}}{( \frac{d}{u} )^2 + \frac{1}{N} \sum_{h=1}^{L} W_h S_h^2}= \frac{\sum_{h=1}^{L} \frac{W_h^2 S_h^2}{w_h}}{ ( \frac{r \overline{Y}}{u} )^2 + \frac{1}{N} \sum_{h=1}^{L} W_h S_h^2}.<br>
\tag{3.30}<br>
$$</p>
<p>根据不同的分配方式：</p>
<ol>
<li>
<p><strong>按比例分配</strong>：$w_h = W_h$</p>
<p>$$<br>
n = \frac{\sum_{h=1}^{L} W_h S_h^2}{V + \frac{\sum_{h=1}^{L} W_h S_h^2}{N}}<br>
\tag{3.31}<br>
$$</p>
</li>
<li>
<p><strong>按最优分配</strong>，$w_h = \frac{W_h S_h / \sqrt{c_h}}{\sum_{h=1}^{L} W_h S_h / \sqrt{c_h}}$，将它直接代入 (3.29) 式，有</p>
<p>$$<br>
n = \frac{( \sum_{h=1}^{L} \frac{W_h S_h}{\sqrt{c_h}} )(\sum_{h=1}^{L} {W_h S_h}{\sqrt{c_h}})}{V + \frac{1}{N} \sum_{h=1}^{L} {W_h S_h^2}}<br>
\tag{3.32}<br>
$$</p>
</li>
<li>
<p><strong>按奈曼分配</strong>，$w_h = \frac{W_h S_h}{\sum_{h=1}^{L} W_h S_h}$</p>
<p>$$<br>
n = \frac{\left( \sum_{h=1}^{L} W_h S_h \right)^2}{V + \frac{1}{N} \sum_{h=1}^{L} W_h S_h^2}<br>
\tag{3.33}<br>
$$</p>
</li>
</ol>
<p>在$W_h&lt;1$条件下，<br>
故奈曼分配样本量小于比例分配样本量</p>
<hr>
<h2 id="五、划分层问题">五、划分层问题</h2>
<h2 id="1-层的界限">1. 层的界限</h2>
<p><strong>累计平方根法</strong>是一种将数据划分为多个层的方法，主要用于在不均匀区间的情况下确定分层边界。该方法通过频数的平方根累计求和来实现。具体步骤如下：</p>
<ol>
<li>
<p><strong>确定每个区间的频数</strong>：首先，计算并记录每个区间内的数据频数，记作 $x$。</p>
</li>
<li>
<p><strong>计算频数的平方根</strong>：对每个区间的频数 $x$ 求平方根。如果区间的大小不一致，需要进行调整。例如，假设标准区间大小为 5，而某个区间的大小为 10，则应使用公式调整平方根：<br>
$$<br>
\sqrt{\frac{\text{频数} \times \text{区间大小}}{\text{标准区间大小}}}<br>
$$</p>
</li>
<li>
<p><strong>累计平方根</strong>：将每个区间的平方根累计求和，得到从第一个区间到最后一个区间的累计平方根值。</p>
</li>
<li>
<p><strong>确定划分点</strong>：根据需要的层数，将总的累计平方根值除以层数，得到每个层的划分间距。然后，根据这个间距划分累积值，以确定每一层的分界点。</p>
</li>
</ol>
<p>此方法通过频数的平方根求和和累积来实现分层，适用于频数不均或区间大小不一致的数据集。</p>
<hr>
<h3 id="2-层数的确定">2. 层数的确定</h3>
<p>但在实际工作中，$Y$ 本身未知，只能通过与 $Y$ 高度相关的辅助指标 $X$ 来进行。这时估计量的方差可以分为两部分，一部分与层数有关，另一部分与层数无关，用模型表示为 $\frac{R^2}{L^2} + (1 - R^2)$，其中 $R^2$ 是方差中受层数影响的部分，$1 - R^2$ 是不受层数影响的部分。因此，当层数增加到一定程度时，在精度上的收益将非常小。</p>
<p>除非 $Y$ 与 $X$ 的相关系数 $\rho &gt; 0.95$，否则层数一般不超过 6 为宜。</p>
<p>同时，分层是需要费用的，因此要考虑增加层数提高的精度与总费用之间的平衡。因为在总费用一定的条件下，增加层数必然导致降低样本量，这时就要考虑增加层数而降低样本量在精度上是否合算。</p>
<hr>
<h2 id="五、其他分层技术">五、其他分层技术</h2>
<h3 id="1-目录抽样">1. 目录抽样</h3>
<p><strong>目录抽样</strong><br>
目录抽样与区域抽样相对应，凡是按照目录名单的抽样框抽取样本，都可以称为目录抽样。<br>
目录抽样在某种意义上是一种特殊的分层抽样，它将总体分为两层，一层全面调查层，一层为抽样调查层。如我国对工业企业的调查，对主营业务收入2000万元以上的采用全面调查，2000万元以下的采用抽样调查。</p>
<p><strong>优缺点</strong>：</p>
<ul>
<li><strong>优点</strong>：操作简便、节省时间和资源。</li>
<li><strong>缺点</strong>：目录可能不总是准确地反映抽样对象的特征，尤其是在分类信息过时或不精确的情况下。</li>
</ul>
<h3 id="2。-事后分层">2。 事后分层</h3>
<p><strong>事后分层</strong><br>
在实际中，有时进行事先分层会存在定的困难。例如:</p>
<ol>
<li>各层的抽样框无法得到。</li>
<li>几个变量都适宜于分层，而要进行事先的多重交叉分层存在一定困难，同时也不需要了解交叉分层后每个子层的信息。</li>
<li>一个单位到底属于哪一层要在收集到样本数据以后才知道。</li>
<li>总体规模 N太大，事先分层太费事等。<br>
在这些情况下，如果还想利用分层抽样在精度上的得益或者想得到每个子总体的估计，就可以采用事后分层(post-stratification) 技术。</li>
</ol>
<p><strong>实施办法</strong>：<br>
先采用简单随机抽样的方法从总体中抽取一个样本量为$N$的样本，然后对样本中的单元按某些特征进行分层。假设在$N$ 个样本中，落入第$h$层样本数为$𝑚_ℎ$，有$∑_{ℎ=1}^𝐿𝑚_ℎ =𝑛$，则此时对总体均值的事后分层估计为<br>
$$<br>
\bar{y}<em>{yst}=\sum</em>{h=1}^L W_h \bar{y}<em>h =\sum</em>{h=1}^L W_h (\frac{1}{𝑚_h}  \sum_{i=1}^{𝑚_h}y_{h_i})<br>
$$<br>
下标“pst”代表“post-stratification”;层权$w_H$已知; $y_{h_i}$代表落入第$h$层的第$i$个样本的指标值。</p>
<p>由于$𝑚_h$代表$n$个样本中落入第$h$层的样本数，所以$𝑚_h$会随抽取样本的不同而发生化，同时$𝑚_h$  $(h=1,2,··,L)$中的一个或更多个可能等于0，如果出现这种情况，在估计之前就需要对层进行合并。<br>
由事后分层估计量方差可知，当样本量足够大时，事后分层的精度与按比例分配事先分层的精度相当。</p>
<h2 id="-2"></h2>
<h1>整群抽样</h1>
<h2 id="一、抽样方法与特点-3">一、抽样方法与特点</h2>
<ul>
<li>
<p>整群抽样（cluster sampling）或集团抽样,是将总体划分为若干群，然后以群为抽样单元，从总体中随机抽取一部分群，对中选群中的所有基本单元进行调查的一种抽样技术。</p>
</li>
<li>
<p>特点：</p>
</li>
</ul>
<ol>
<li><strong>抽样框编制得以简化</strong>：在大规模抽样调查中，常常没有或很难编制出包括总体所有次级单元在内的抽样框，而整群抽样则不需要编制庞大的抽样框。</li>
<li><strong>实施调查便利，节省费用</strong></li>
<li><strong>整群抽样的随机性</strong>体现在群与群间不重叠，也无遗漏，总体任何一个基本单元都必须且只能归于某一群,<strong>群的抽选按概率确定</strong>。</li>
<li>如果把每一个群看作一个单位，则整群抽样可以被理解为是一种<strong>特殊的简单随机抽样</strong>。理解这一点对给出整群抽样的估计量的方差有帮助.</li>
<li>整群抽样也是<strong>多阶段抽样的前提和基础</strong>。</li>
<li>整群抽样有<strong>特殊的用途</strong>。有些现象的研究，如果直接调查作为基本单元的个体，很难说明问题，必须以一定范围所包括的基本单元为群体，进行整群抽样，才能满足调查的目的。</li>
<li>整群抽样要求分群后各群所含次级单元数目应该确知，否则会给抽样推断带来不便。</li>
<li>整群抽样由于调查单位只能集中在若干群上，而不能均匀分布在总体的各个部分，因此，它的<strong>精度比起简单随机抽样来要低一些</strong>。</li>
</ol>
<hr>
<h2 id="二、估计量与估计量性质-3">二、估计量与估计量性质</h2>
<h3 id="估计量：">估计量：</h3>
<blockquote>
<h4 id="群规模相等时均值估计：">群规模相等时均值估计：</h4>
<p>$$\hat{\overline{\overline{Y}}}={\overline{\overline{y}}}=\sum_{i=1}^n\sum_{j=1}^M \frac{y_{ij}}{nM}=\frac{1}{n}\sum_{i=1}^n \bar{y_i}$$</p>
</blockquote>
<blockquote>
<h4 id="群规模相等时比例估计：">群规模相等时比例估计：</h4>
<p>$$\overline{y} = \frac{\sum_{i=1}^n y_i}{n} = p$$<br>
$$y_i =<br>
\begin{cases}<br>
1, &amp; \text{具有某种性质} \<br>
0, &amp; \text{其他}<br>
\end{cases}$$<br>
$$<br>
p = \frac{1}{n} \sum_{i=1}^n p_i = \frac{1}{nM} \sum_{i=1}^n A_i<br>
$$</p>
</blockquote>
<h4 id="群规模不等时均值估计：">群规模不等时均值估计：</h4>
<blockquote>
<h5 id="等概抽样简单估计">等概抽样简单估计</h5>
<p>$$\hat{\overline{\overline{Y}}}=<br>
\overline{\overline{y}} = \frac{1}{n} \sum_{i=1}^n \overline{y_i} = \frac{1}{n} \sum_{i=1}^n \left( \sum_{j=1}^{M_i}\frac{ y_{ij}}{M_i} \right)<br>
$$</p>
</blockquote>
<blockquote>
<h5 id="等概抽样加权估计">等概抽样加权估计</h5>
<p>$$\hat{\overline{\overline{Y}}}=\overline{\overline{y}} = \sum_{i=1}^n \frac{M_i\bar{y_i}}{n\bar{M}}=\frac{1}{n\bar{M}}\sum_{i=1}^{n}y_i=\frac{\bar{y}}{\bar{M}}=\frac{\bar{y}N}{\bar{M}N}=\frac{\hat{Y}}{M_0}$$<br>
若总体平均规模未知，可用样本平均规模代替。<br>
$$\hat{Y}=M_0\overline{\overline{y}}=N\bar{y}=\frac{N}{n}\sum_{i=1}^{n}y_i$$</p>
</blockquote>
<blockquote>
<h5 id="等概抽样比例估计">等概抽样比例估计</h5>
<p>$$\hat{\overline{\overline{Y}}}=\overline{\overline{y}} = \frac{\sum_{i=1}^n y_i}{\sum_{i=1}^n M_i}$$<br>
$$\hat{Y}=M_0\overline{\overline{y}} = M_0\frac{\sum_{i=1}^n y_i}{\sum_{i=1}^n M_i}$$</p>
</blockquote>
<blockquote>
<h4 id="群规模不等时比例估计：">群规模不等时比例估计：</h4>
<p>群的抽取：采用简单随机抽样，则总体比例的估计量：<br>
$$P = \frac{\sum_{i=1}^n A_i}{\sum_{i=1}^n M_i}$$</p>
</blockquote>
<hr>
<h3 id="对应性质（期望和方差）：-2">对应性质（期望和方差）：</h3>
<h4 id="群规模相等时均值估计：-2">群规模相等时均值估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>无偏估计</strong><br>
$E（\hat{\overline{\overline{Y}}}）=E（{\overline{\overline{y}}}）=\frac{\overline{Y}}{M}=\overline{\overline{Y}}$</p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>方差</strong><br>
$V（\hat{\overline{\overline{Y}}}）=V（{\overline{\overline{y}}}）=\frac{1-f}{n}\frac{1}{N-1}\sum_{i=1}^N(\overline{Y_i}-\overline{\overline{Y}})^2=\frac{1-f}{nM}S_b^2$</p>
</li>
<li>
<p><strong>性质 3</strong>：<strong>方差无偏估计</strong><br>
用$s_b^2$估计$S_b^2$即可：<br>
$v（\hat{\overline{\overline{Y}}}）=v（{\overline{\overline{y}}}）=\frac{1-f}{nM}s_b^2$</p>
</li>
</ul>
<h4 id="群规模相等时比例估计：-2">群规模相等时比例估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>无偏估计</strong></p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>方差</strong><br>
$<br>
V§ = \frac{1 - f}{n} \cdot \frac{\sum_{i=1}^N (P_i - P)^2}{N - 1}<br>
$</p>
</li>
<li>
<p><strong>性质 3</strong>：<strong>方差无偏估计</strong><br>
$<br>
v§ = \frac{1 - f}{n(n - 1)} \sum_{i=1}^n (p_i - p)^2<br>
$</p>
</li>
</ul>
<hr>
<p><strong>群规模不等时均值估计：</strong></p>
<h4 id="等概抽样简单估计：">等概抽样简单估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>有偏估计</strong></p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>方差</strong><br>
$V（\hat{\overline{\overline{Y}}}）=V（{\overline{\overline{y}}}）=\frac{1-f}{n}\frac{1}{N-1}\sum_{i=1}^N(\overline{Y_i}-\overline{\overline{Y}})=\frac{1-f}{nM}S_b^2$</p>
</li>
<li>
<p><strong>性质 3</strong>：<strong>方差估计</strong><br>
用$s_b^2$估计$S_b^2$即可：<br>
$v（\hat{\overline{\overline{Y}}}）=v（{\overline{\overline{y}}}）=\frac{1-f}{nM}s_b^2$</p>
</li>
</ul>
<h4 id="等概抽样加权估计：">等概抽样加权估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>无偏估计</strong></p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>方差</strong><br>
$V（\hat）=V（{N{\overline{y}}}）=N^2\frac{1-f}{n}\frac{1}{N-1}\sum_{i=1}^N({Y_i}-{\overline{Y}})$</p>
</li>
<li>
<p><strong>性质 3</strong>：<strong>方差无偏估计</strong><br>
$v（\hat）=v（{N{\overline{y}}}）=N^2\frac{1-f}{n}\frac{1}{n-1}\sum_{i=1}^N({y_i}-{\overline{y}})$</p>
</li>
</ul>
<h4 id="等概抽样比例估计：">等概抽样比例估计：</h4>
<ul>
<li>
<p><strong>性质 1</strong>：<strong>有偏估计</strong></p>
</li>
<li>
<p><strong>性质 2</strong>：<strong>方差</strong><br>
$$<br>
V(\overline{\overline{y}}) \approx \frac{1 - f}{n\overline{M}^2} \cdot \frac{\sum_{i=1}^n (Y_i - M_i \overline{\overline{Y}})^2}{N - 1}<br>
$$</p>
</li>
</ul>
<p>$$<br>
=\frac{1 - f}{n\overline{M}^2} \cdot \frac{\sum_{i=1}^n M_i^2(\overline{Y_i} -  \overline{\overline{\overline{Y}}})^2}{N - 1}<br>
$$</p>
<p>$$<br>
V(\hat{Y}) \approx N^2\frac{1 - f}{n\overline{M}^2} \cdot \frac{\sum_{i=1}^n (Y_i - M_i \overline{\overline{Y}})^2}{N - 1}<br>
$$</p>
<p>$$<br>
=N^2\frac{1 - f}{n\overline{M}^2} \cdot \frac{\sum_{i=1}^n M_i^2(\overline{Y_i} -  \overline{\overline{\overline{Y}}})^2}{N - 1}<br>
$$</p>
<ul>
<li><strong>性质 3</strong>：<strong>方差无偏估计</strong><br>
$$<br>
v(\overline{\overline{y}}) = \frac{1 - f}{n\overline{M}^2} \cdot \frac{\sum_{i=1}^n (y_i - M_i \overline{\overline{y}})^2}{n - 1}<br>
$$</li>
</ul>
<p>$$<br>
= \frac{1 - f}{n\overline{M}^2} \cdot \frac{1}{n - 1} \left( \sum_{i=1}^n y_i^2 + \overline{\overline{y}}^2 \sum_{i=1}^n M_i^2 - 2\overline{\overline{y}} \sum_{i=1}^n M_i y_i \right)<br>
$$</p>
<p>$$<br>
v({\hat{Y}}) = N^2\frac{1 - f}{n\overline{M}^2} \cdot \frac{\sum_{i=1}^n (y_i - M_i \overline{\overline{y}})^2}{n - 1}<br>
$$</p>
<p>$$<br>
= N^2\frac{1 - f}{n\overline{M}^2} \cdot \frac{1}{n - 1} \left( \sum_{i=1}^n y_i^2 + \overline{\overline{y}}^2 \sum_{i=1}^n M_i^2 - 2\overline{\overline{y}} \sum_{i=1}^n M_i y_i \right)<br>
$$</p>
<h4 id="群规模不等时比例估计：-2">群规模不等时比例估计：</h4>
<ul>
<li><strong>性质 1</strong>：<strong>方差</strong><br>
$$<br>
V§ \approx \frac{1 - f}{n\bar{M}^2} \cdot \frac{\sum_{i=1}^N (A_i - P M_i)^2}{N - 1}<br>
$$</li>
</ul>
<p>$$<br>
= \frac{1 - f}{n\bar{M}^2} \cdot \frac{\sum_{i=1}^N M_i^2 (P_i - P)^2}{N - 1}<br>
$$</p>
<ul>
<li><strong>性质2</strong>：<strong>方差的估计</strong></li>
</ul>
<p>$$<br>
v§ = \frac{1 - f}{n\bar{M}^2} \cdot \frac{\sum_{i=1}^n (A_i - p M_i)^2}{n - 1}<br>
$$</p>
<p>$$<br>
= \frac{1 - f}{n\bar{M}^2} \cdot \frac{\left( \sum_{i=1}^n A_i^2 + p^2 \sum_{i=1}^n M_i^2 - 2p \sum_{i=1}^n A_i M_i \right)}{n - 1}<br>
$$</p>
<p>若$\bar{M}$未知，可用样本值 $\overline{m}$ 替代。</p>
<hr>
<h2 id="三、群的划分">三、群的划分</h2>
<h3 id="1-原则：">1. 原则：</h3>
<p>划分群时应使<strong>群内方差尽可能大,群间方差尽可能小</strong>。<br>
这意味着每个群均具有足够的代表性。如果划分的群相互之间颇多相似之处，那么少量群的抽取足以提供良好的精度。</p>
<blockquote>
<p>原因:由于整群抽样是对入选群中的所有单元都进行调查,因此<strong>影响整群抽样误差的主要是群间方差</strong>。为了提高整群抽样估计的精度,划分群时应使群内方差尽可能大,群间方差尽可能小。</p>
</blockquote>
<h3 id="2-一些方案：">2.一些方案：</h3>
<ol>
<li>根据行政或地域形成的群体;<br>
如:村庄、城镇、一片森林等</li>
<li>调查人员人为确定的;<br>
对可控制规模的群，群规模不宜过大</li>
</ol>
<h2 id="四、-群的规模（群的单元的数量）">四、 群的规模（群的单元的数量）</h2>
<p>即组成群的单元的数量。整群抽样中，如何有效地对群的大小进行计量，直接关系到抽样估计效率的高低。研究表明，对群的大小的最优计量尺度是各群在所研究标志上的标志总量大小。但在实际工作中，它是未知的。因此通常选择与所研究标志高度线性相关的另一辅助标志作为计量尺度。</p>
<ul>
<li>群的规模大,估计的精度差但费用省;群的规模小,估计的精度高但费用增大。</li>
<li>当各群所含次级单元数相等时，就称群的大小相等；当各群所含次级单元数不相等时，就称群的大小不相等。</li>
<li>当群的大小接近时，常采用简单随机抽样抽取群；</li>
<li>当群的大小相差比较大时，为提高效率则更多地采用不等概率（按与群的大小成比例的概率抽样）方法。</li>
</ul>
<h2 id="五、-整群抽样效率分析">五、 整群抽样效率分析</h2>
<ul>
<li>整群抽样的估计精度与群内相关系数$\rho$有关。</li>
</ul>
<p>$$<br>
\rho = \frac{E\left( (Y_{ij} - \overline{\overline{Y}})(Y_{ik} - \overline{\overline{Y}}) \right)}{E\left( (Y_{ij} - \overline{\overline{Y}})^2 \right)}<br>
$$</p>
<p><strong>分子可写成：</strong></p>
<p>$$<br>
\frac{\sum_{i=1}^N \sum_{j &lt; k}^M (Y_{ij} - \overline{\overline{Y}})(Y_{ik} - \overline{\overline{Y}})}{\frac{NM(M-1)}{2}}<br>
$$</p>
<p>大分母可看作$NC_M^2$</p>
<p>分母可写成：<br>
$$<br>
\frac{\sum_{i=1}^N \sum_{j &lt; k}^M (Y_{ij} -\overline{\overline{Y}})^2}{NM} = \frac{NM - 1}{MN} S^2<br>
$$</p>
<p>于是$\rho$又可以写成：<br>
$$<br>
\rho = \frac{2 \sum_{i=1}^N \sum_{j &lt; k}^M (Y_{ij} -\overline{\overline{Y}})(Y_{ik} - \overline{\overline{Y}})}{(M - 1)(NM - 1)S^2}<br>
$$</p>
<p>$\overline{\overline{y}}$ 的方差可以用群内相关系数近似表示：</p>
<p>$$<br>
V(\overline{y}) = \frac{1}{M^2} V(\overline{y})<br>
$$</p>
<p>$$<br>
= \frac{1 - f}{nM^2} \cdot \frac{1}{N - 1} \sum_{i=1}^N (Y_i - \overline{Y})^2<br>
$$</p>
<p>$$<br>
= \frac{1 - f}{n} \cdot \frac{1}{M^2(N - 1)} \cdot \sum_{i=1}^N \left[ \sum_{j=1}^M (Y_{ij} - \overline{Y}) \right]^2<br>
$$</p>
<p>$$<br>
= \frac{1 - f}{n} \cdot \frac{NM - 1}{M^2(N - 1)} S^2 \times \left[ 1 + (M - 1)\rho \right]<br>
$$</p>
<p>$$<br>
\approx \frac{1 - f}{nM} S^2 \left[ 1 + (M - 1)\rho \right] \quad \text{(当 $N - 1 = N$，$NM - 1 = NM$ 时)}<br>
$$</p>
<p><strong>补充：</strong><br>
$$<br>
\sum_{i=1}^N \left( Y_i - \overline{Y} \right)^2 = \sum_{i=1}^N \left[ \sum_{j=1}^M \left( Y_{ij} - \overline{Y} \right) \right]^2<br>
$$</p>
<p>$$<br>
= \sum_{i=1}^N \left[ \sum_{j=1}^M \left( Y_{ij} - \overline{Y} \right)^2 + 2 \sum_{j &lt; k}^M \left( Y_{ij} - \overline{Y} \right) \left( Y_{ik} - \overline{Y} \right) \right]<br>
$$</p>
<p>$$<br>
= (NM - 1)S^2 + (NM - 1)(M - 1)S^2 \rho<br>
$$</p>
<p>$$<br>
= (NM - 1)S^2 \left[ 1 + (M - 1)\rho \right]<br>
$$</p>
<hr>
<ul>
<li>
<p>若采用简单随机抽样，则样本均值 $\overline{y}$ 的方差为：<br>
$$<br>
V_{srs}(\overline{y}) = \frac{1 - f}{nM} S^2<br>
$$</p>
</li>
<li>
<p>等群抽样的设计效应为：<br>
$$<br>
deff = \frac{V(\overline{y})}{V_{srs}(\overline{y})} \approx 1 + (M - 1)\rho<br>
$$</p>
</li>
<li>
<p>说明整群抽样的方差约为简单随机抽样方差的 $1 + (M - 1)\rho$ 倍。</p>
</li>
</ul>
<hr>
<p>补充：<br>
此外，群内相关系数也可以用群内方差 $S_w^2$ 和群间方差 $S_b^2$ 表示：</p>
<p>$$<br>
\hat{\rho} = \frac{S_b^2 - S_w^2}{S_b^2 + (M - 1)S_w^2}<br>
$$</p>
<p>当群间方差等于0，即各群均值 $\overline{Y}_i$ 都相等时，$\rho$ 有极小值 $-\frac{1}{M-1}$，所以 $\rho$ 的取值范围是 $\left[ -\frac{1}{M-1}, 1 \right]$。</p>
<ul>
<li>
<p><strong>当 $\rho = 1$ 时，$\textbf{deff} = M$</strong><br>
群内方差为0。</p>
</li>
<li>
<p><strong>当 $\rho = 0$ 时，$\textbf{deff} = 1$</strong><br>
群间方差为0。</p>
</li>
<li>
<p><strong>当 $\rho$ 为负时，$\textbf{deff} &lt; 1$</strong><br>
群内方差大于总体方差相等。</p>
</li>
</ul>
<hr>
<h1>二阶段抽样</h1>
<h2 id="一、抽样方法与特点-4">一、抽样方法与特点</h2>
<h3 id="概述：">概述：</h3>
<p>在整群抽样中，如果抽中的群内所含的次级单元个数相当地多，此时对该群作普查会感到“心有余而力不足”。<br>
特别当群内的次级单元差异不大，即 $\rho$ 比较大，这种情况下对群内所有的次级单元——访问似乎完全没有必要，一个省时省钱又省力的念头会在调查者的头脑中油然而生：何不在抽到的群内再作一定方式的抽样呢？这种在选中的初级单元中再进行抽样的方法称为<strong>二阶段抽样</strong>。<br>
倘若在抽取的次级单元中又包含许多更次一级的单元，在这些单元中继续抽样就自然地称为<strong>三阶段抽样</strong>。</p>
<h3 id="定义：-2">定义：</h3>
<p>设总体由N个初级单元组成，每个初级单元又由若干次级单元组成，若在总体中按一定方法抽取n个初级单元，对每个被抽中的初级单元再抽取若干次级单元进行调查，这种抽样称为二阶抽样。</p>
<p>如果第一阶段抽样采用全面调查，二阶抽样就成了分层抽样；<br>
如果第二阶段抽样采用全面调查，二阶抽样就成了整群抽样。</p>
<h3 id="二阶与多阶抽样的优点：">二阶与多阶抽样的优点：</h3>
<ol>
<li><strong>抽样框获取方便</strong><br>
它具有实施上的方便，比如在编制抽样框时那些没有被抽到的群或次一级群内的单元就没有必要也去编制抽样框。仅需对那些已抽中的单元才去准备下一级单元的抽样框，而且许多抽样调查常常采用行政系统及隶属单元，这给多阶抽样本身创造了有利的条件。<br>
能够满足各级政府部门对抽样调查资料的需求。因为各级政府领导都关心全国和本地区、本部门的社会经济发展状况，希望抽样调查能同时满足全国性和地方性的需要。因而采用二阶或多阶抽样，在一定程度上能够满足各级政府、部门对调查资料的需求。</li>
<li><strong>抽样方式灵活，有利于提高抽烟的估计效率</strong><br>
有利于减少抽样误差、提高抽样估计精度。这种抽样调查方法，可以使每个一阶样本单位分布比较均匀，具有很好的代表性；对于方差大的阶段多抽些样本单位以提高精度。</li>
<li><strong>保持样本分布集中的优点，克服由样本相似性引起的效率降低问题</strong></li>
</ol>
<h2 id="二、理论基础">二、理论基础</h2>
<p><strong>性质1</strong>：对于两阶段抽样，有</p>
<p><strong>(1)</strong><br>
$$<br>
\mathbb{E}(\hat{\theta}) = \mathbb{E}_1 \mathbb{E}<em>2 (\hat{\theta}) = \mathbb{E}(\mathbb{E}(\hat{\theta}</em>{\Omega_2} \mid \Omega_1))<br>
$$</p>
<p><strong>(2)</strong><br>
$$<br>
\mathbb{V}(\hat{\theta}) = \mathbb{V}_1 \mathbb{E}_2 (\hat{\theta}) + \mathbb{E}_1 \mathbb{V}_2 (\hat{\theta})<br>
$$</p>
<p>式中，$\mathbb{E}_2, \mathbb{V}_2$ 为在固定初级单元时对第二阶段抽样求均值和方差；$\mathbb{E}_1, \mathbb{V}_1$ 为对第一阶段抽样求均值和方差。</p>
<p>证明：</p>
<p>记 $\mathbb{E}(\hat{\theta}) = \tilde{\theta}$</p>
<p>$$<br>
V(\hat{\theta}) = \mathbb{E}(\hat{\theta} - \tilde{\theta})^2 = \mathbb{E}_1 \left[ \mathbb{E}_2 (\hat{\theta} - \tilde{\theta})^2 \right]<br>
$$</p>
<p>由 $\mathbb{E}_2 (\hat{\theta} - \tilde{\theta})^2 = \mathbb{E}_2((\hat{\theta})^2) - 2\tilde{\theta} \mathbb{E}_2(\hat{\theta}) + \tilde{\theta}^2$<br>
$<br>
= [\mathbb{E}_2(\hat{\theta})]^2 + V_2(\hat{\theta}) - 2\tilde{\theta} \mathbb{E}_2(\hat{\theta}) + \tilde{\theta}^2<br>
$</p>
<p>对上述两边求 $\mathbb{E}_1$，得</p>
<p>$$<br>
V(\hat{\theta}) = \mathbb{E}_1 \left{ [\mathbb{E}_2(\hat{\theta})]^2 + V_2(\hat{\theta}) - 2\tilde{\theta} \mathbb{E}_2(\hat{\theta}) + \tilde{\theta}^2 \right}<br>
$$</p>
<p>$$<br>
= \mathbb{E}_1 {[\mathbb{E}_2 (\hat{\theta})]^2} + \mathbb{E}_1 [V_2 (\hat{\theta})] - 2\tilde{\theta} \mathbb{E}_1 [\mathbb{E}_2(\hat{\theta})] + \tilde{\theta}^2<br>
$$</p>
<p>$$<br>
= \mathbb{E}_1 {[\mathbb{E}_2 (\hat{\theta})]^2} + \mathbb{E}_1 [V_2 (\hat{\theta})] - {\mathbb{E}_1 [\mathbb{E}_2(\hat{\theta})]}^2<br>
$$</p>
<p>$$<br>
= \mathbb{E}_1 {[\mathbb{E}_2 (\hat{\theta})]^2} - {\mathbb{E}_1 [\mathbb{E}_2 (\hat{\theta})]}^2 + \mathbb{E}_1 [V_2 (\hat{\theta})]<br>
$$</p>
<p>$$<br>
= V_1 [\mathbb{E}_2 (\hat{\theta})] + \mathbb{E}_1 [V_2 (\hat{\theta})]<br>
$$</p>
<h2 id="二、估计量与估计量性质-4">二、估计量与估计量性质</h2>
<h3 id="1-初级单元大小相等时的二阶抽样">1. 初级单元大小相等时的二阶抽样</h3>
<h4 id="均值估计"><strong>均值估计</strong></h4>
<p>$$<br>
\hat{\overline{\overline{Y}}}=\overline{\overline{y}} = \frac{1}{n} \sum_{i=1}^n \overline{y}<em>i = \frac{1}{nm} \sum</em>{i=1}^n \sum_{j=1}^m y_{ij}<br>
$$</p>
<p><strong>性质1</strong>：无偏估计</p>
<p><strong>性质2</strong>： 方差<br>
其方差为：</p>
<p>$$<br>
\text{V}(\overline{\overline{y}}) = \frac{1 - f_1}{n} S_1^2 + \frac{1 - f_2}{nm} S_2^2<br>
$$</p>
<p><strong>性质3</strong>：方差的无偏估计：</p>
<p>$$<br>
v(\overline{\overline{y}}) = \frac{1 - f_1}{n} s_1^2 + \frac{f_1 (1 - f_2)}{nm} s_2^2<br>
$$</p>
<hr>
<h4 id="总值估计"><strong>总值估计</strong></h4>
<p><strong>性质1</strong>：<br>
$$<br>
\tilde{Y} = NM \cdot \overline{\overline{y}}<br>
$$</p>
<p><strong>性质2</strong>： 方差<br>
$$<br>
V(\tilde{Y}) = (NM)^2 \cdot V(\overline{y})<br>
$$</p>
<h2 id="性质3：方差的无偏估计：-v-tilde-Y-NM-2-cdot-v-overline-y"><strong>性质3</strong>：方差的无偏估计：<br>
$$<br>
v(\tilde{Y}) = (NM)^2 \cdot v(\overline{y})<br>
$$</h2>
<h4 id="补充：">补充：</h4>
<p><strong>定理</strong>：若两阶段的抽样都是简单随机抽样的，则：</p>
<p><strong>(1)</strong> $\overline{\overline{y}}$ 是 $\overline{Y}$ 的无偏估计量；</p>
<hr>
<p><strong>(2)</strong><br>
$$<br>
\mathbb{V}(\overline{y}) = \frac{1 - f_1}{n} S_1^2 + \frac{1 - f_2}{mn} S_2^2<br>
$$<br>
其中<br>
$$<br>
S_1^2 = \frac{1}{N - 1} \sum_{i=1}^N (\overline{Y}<em>i - \overline{Y})^2,<br>
$$<br>
$$<br>
S_2^2 = \frac{1}{N} \sum</em>{i=1}^N S_{2i}^2 = \frac{1}{N(M-1)} \sum_{i=1}^N \sum_{j=1}^M (Y_{ij} - \overline{Y}_i)^2<br>
$$</p>
<hr>
<p><strong>(3)</strong><br>
$$<br>
v(\overline{y}) = \frac{1 - f_1}{n} s_1^2 + \frac{f_1(1 - f_2)}{mn} s_2^2<br>
$$<br>
其中</p>
<p>$$<br>
s_1^2 = \frac{1}{n - 1} \sum_{i=1}^n (\overline{y}<em>i - \overline{y})^2,<br>
$$<br>
$$<br>
s_2^2 = \frac{1}{n} \sum</em>{i=1}^n s_{2i}^2 = \frac{1}{n(m - 1)} \sum_{i=1}^n \sum_{j=1}^m (y_{ij} - \overline{y}_i)^2<br>
$$</p>
<blockquote>
<p>证明可以借助“理论基础”易得。</p>
</blockquote>
<h4 id="总值估计-2"><strong>总值估计</strong></h4>
<p><strong>性质1</strong>：<br>
$$<br>
\tilde{Y} = NM \cdot \overline{\overline{y}}<br>
$$</p>
<p><strong>性质2</strong>： 方差<br>
$$<br>
V(\tilde{Y}) = (NM)^2 \cdot V(\overline{y})<br>
$$</p>
<p><strong>性质3</strong>：方差的无偏估计：<br>
$$<br>
v(\tilde{Y}) = (NM)^2 \cdot v(\overline{y})<br>
$$</p>
<h3 id="2-初级单元大小不等时的二阶抽样">2. 初级单元大小不等时的二阶抽样</h3>
<ul>
<li><strong>第一阶段抽样</strong>：按简单随机抽样从$N$个初级单元中抽取$n$个；</li>
<li><strong>第二阶段抽样</strong>：按简单随机抽样，在抽中的初级单元中分别独立抽取次级单元。</li>
</ul>
<hr>
<h4 id="1-简单估计：">(1) 简单估计：</h4>
<p>$$<br>
\hat{Y} = \frac{N}{n} \sum_{i=1}^n \hat{Y}<em>i = N \frac{\sum</em>{i=1}^n M_i \overline{y}_i}{n}<br>
$$</p>
<p><strong>性质1</strong>：无偏估计<br>
$$<br>
\mathbb{E}(\hat{Y}) = \mathbb{E}_1 \left[ \mathbb{E}_2 (\hat{Y}_u) \right]<br>
$$</p>
<p>$$<br>
= \mathbb{E}_1 \left[ \mathbb{E}<em>2 \left( N \frac{\sum</em>{i=1}^n M_i \overline{y}_i}{n} \right) \right]<br>
= \mathbb{E}<em>1 \left[ N \frac{\sum</em>{i=1}^n M_i \mathbb{E}_2 (\overline{y}_i)}{n} \right]<br>
$$</p>
<p>$$<br>
= \mathbb{E}<em>1 \left[ N \frac{\sum</em>{i=1}^n M_i \overline{Y}_i}{n} \right]<br>
= \mathbb{E}<em>1 \left[ N \frac{\sum</em>{i=1}^n Y_i}{n} \right]<br>
$$</p>
<p>$$<br>
= N \mathbb{E}<em>1 \left[ \frac{1}{n} \sum</em>{i=1}^n Y_i \right] = Y<br>
$$</p>
<p><strong>性质2</strong>：方差：</p>
<p>$$<br>
V(\hat{Y}) = N^2 \frac{1 - f_1}{n} \sum_{i=1}^N \frac{(Y_i - \overline{Y})^2}{N-1} + \frac{N}{n} \sum_{i=1}^N \frac{M_i^2 (1 - f_{2i}) S_{2i}^2}{m_i}<br>
$$</p>
<p>$$<br>
V(\hat{Y}) = V_1 \left[ \mathbb{E}<em>2 \left( N \frac{\sum</em>{i=1}^n M_i \overline{y}_i}{n} \right) \right] + \mathbb{E}<em>1 \left[ V_2 \left( N \frac{\sum</em>{i=1}^n M_i \overline{y}_i}{n} \right) \right]<br>
$$</p>
<p>$$<br>
= V_1 \left[ N \frac{\sum_{i=1}^n M_i \overline{Y}_i}{n} \right] + \mathbb{E}<em>1 \left[ N^2 \frac{\sum</em>{i=1}^n M_i^2 V(\overline{y}_i)}{n^2} \right]<br>
$$</p>
<p>$$<br>
= V_1 \left[ N \frac{\sum_{i=1}^n Y_i}{n} \right] + \mathbb{E}<em>1 \left[ N^2 \frac{\sum</em>{i=1}^n M_i^2 \frac{1 - f_{2i}}{m_i} S_{2i}^2}{n^2} \right]<br>
$$</p>
<p>$$= N^2 \frac{1 - f_1}{n} \frac{\sum_{i=1}^N (Y_i - \overline{Y})^2}{N - 1} + N^2 \frac{1}{n} \mathbb{E}<em>1 \left[ \frac{\sum</em>{i=1}^n \frac{M_i^2 (1 - f_{2i}) S_{2i}^2}{m_i}}{N} \right]<br>
$$</p>
<p>$$= N^2 \frac{1 - f_1}{n} \frac{\sum_{i=1}^N (Y_i - \overline{Y})^2}{N - 1} + N^2 \frac{1}{n} \cdot \sum_{i=1}^N \frac{M_i^2 (1 - f_{2i}) S_{2i}^2}{Nm_i}<br>
$$</p>
<p>$$= N^2 \frac{1 - f_1}{n} \frac{\sum_{i=1}^N (Y_i - \overline{Y})^2}{N - 1} + \frac{N}{n} \sum_{i=1}^N \frac{M_i^2 (1 - f_{2i}) S_{2i}^2}{m_i}<br>
$$</p>
<p><strong>性质3</strong>:方差的无偏估计:</p>
<p>$$<br>
v(\hat{Y}) = N^2 \frac{1 - f_1}{n} \sum_{i=1}^n \frac{(\hat{Y}<em>i - \hat{\bar{Y}})^2}{n - 1} + \frac{N}{n} \sum</em>{i=1}^n \frac{M_i^2 (1 - f_{2i}) s_{2i}^2}{m_i}<br>
$$</p>
<h4 id="2-比估计：">(2) 比估计：</h4>
<p>$$<br>
Y = M_0 \frac{\sum_{i=1}^N Y_i}{\sum_{i=1}^N M_i},<br>
$$</p>
<p>可用比估计，以 $M_i$ 为辅助变量：</p>
<p>$$<br>
\hat{Y}<em>R = M_0 \frac{\sum</em>{i=1}^n \hat{Y}<em>i}{\sum</em>{i=1}^n M_i}.<br>
$$</p>
<p><strong>性质2</strong> 方差近似为：</p>
<p>$$<br>
V(\hat{Y}<em>R) \approx \text{MSE}(\hat{Y}<em>R) \approx N^2 \frac{1 - f_1}{n} \frac{\sum</em>{i=1}^N M_i^2 (\overline{Y}<em>i - \overline{Y})^2}{N - 1} + \frac{N}{n} \sum</em>{i=1}^N \frac{M_i^2 (1 - f</em>{2i}) S_{2i}^2}{m_i},<br>
$$</p>
<p>其中：</p>
<p>$$<br>
S_{2i}^2 = \frac{\sum_{j=1}^{M_i} (Y_{ij} - \overline{Y}_i)^2}{M_i - 1}.<br>
$$</p>
<p><strong>性质3</strong> 方差的无偏估计为：</p>
<p>$$<br>
v(\hat{Y}<em>R) \approx N^2 \frac{1 - f_1}{n} \frac{\sum</em>{i=1}^n M_i^2 (\overline{y}<em>i - \hat{Y}<em>R)^2}{n - 1} + \frac{N}{n} \sum</em>{i=1}^n \frac{M_i^2 (1 - f</em>{2i}) s_{2i}^2}{m_i},<br>
$$</p>
<p>其中：</p>
<p>$$<br>
s_{2i}^2 = \frac{\sum_{j=1}^{m_i} (y_{ij} - \overline{y}_i)^2}{m_i - 1}.<br>
$$</p>
<hr>
<h2 id="三、样本量的确定">三、样本量的确定</h2>
<h3 id="1-初级单元大小相等时，最优样本量-m-与-n-的确定：">1.初级单元大小相等时，最优样本量 $m$ 与 $n$ 的确定：</h3>
<p><strong>m的确定</strong><br>
线性费用函数：</p>
<p>$$<br>
\mathbf{C_T} = c_0 + c_1 n + c_2 nm<br>
$$</p>
<hr>
<ol>
<li></li>
</ol>
<p>$$<br>
V(\overline{\overline{y}}) = \frac{1 - f_1}{n} S_1^2 + \frac{1 - f_2}{mn} S_2^2<br>
$$</p>
<p>$$<br>
= \frac{1}{n} \left( S_1^2 - \frac{S_2^2}{M} \right) + \frac{S_2^2}{nm} - \frac{S_1^2}{N}<br>
$$</p>
<ol start="2">
<li></li>
</ol>
<p>$$<br>
\left( V(\overline{\overline{y}}) + \frac{S_1^2}{N} \right) \left( C_T - c_0 \right) = \left[ \frac{1}{n} \left( S_1^2 - \frac{S_2^2}{M} \right) + \frac{S_2^2}{nm} \right] (c_1 n + c_2 nm)<br>
$$</p>
<p>$$<br>
= \left[ \left( S_1^2 - \frac{S_2^2}{M} \right) + \frac{S_2^2}{m} \right] (c_1 + c_2 m) \geq \left( \sum_{i=1}^n \sqrt{a_i} \sqrt{b_i} \right)^2<br>
$$</p>
<p>根据柯西-许瓦兹不等式，达到最小值的充要条件是：</p>
<p>$$<br>
\frac{\sqrt{\left( S_1^2 - S_2^2 / M \right)}}{\sqrt{c_1}} = \frac{\sqrt{S_2^2 / m}}{\sqrt{c_2 m}}<br>
$$</p>
<p>因此 $m$ 的最优值为：</p>
<p>$$<br>
m_{\text{opt}} = \frac{S_2 / \sqrt{c_2}}{\sqrt{\left( S_1^2 - \frac{S_2^2}{M} \right)} / \sqrt{c_1}} = \frac{S_2}{\sqrt{\left( S_1^2 - \frac{S_2^2}{M} \right)} }\sqrt{\frac{c_1}{c_2}}<br>
$$</p>
<p>令 $m’$ 为 $m_{\text{opt}}$ 的整数部分，则 $m$ 的取值规则为：</p>
<ul>
<li>
<p>当 $m_{\text{opt}}^2 &gt; m’ (m’ + 1)$，则取 $m = m’ + 1$；</p>
</li>
<li>
<p>当 $m_{\text{opt}}^2 \leq m’ (m’ + 1)$，则取 $m = m’$；</p>
</li>
<li>
<p>当 $m_{\text{opt}} &gt; M$ 或 $\left( S_1^2 - \frac{S_2^2}{M} \right) &lt; 0$，则取 $m = M$；</p>
</li>
</ul>
<p>$m$ 确定后，再根据 $\mathbf{C_T}$ 或 $\mathbf{V}$ 求出 $n$。</p>
<h1>πPS抽样</h1>
<p>πPS抽样是一种特殊的不放回不等概抽样，其性质包括：</p>
<ul>
<li><strong>不放回抽样</strong>：相对效率较高，但估计量方差计算复杂，缺乏操作性（实施困难）。</li>
<li><strong>包含概率要求</strong>：总体中每个单元的包含概率与其规模成比例。</li>
<li><strong>样本量要求</strong>：样本量 $n$ 固定。</li>
</ul>
<h3 id="特别说明">特别说明</h3>
<ul>
<li>
<p>如果每个单元的入样概率与其大小或规模严格成比例，则对于固定的 $n$，有：<br>
$$<br>
\pi_i = n \frac{M_i}{M_0} = n Z_i<br>
$$<br>
这种情形的抽样称为<strong>严格的πPS抽样</strong>。</p>
</li>
<li>
<p>πPS抽样下二阶包含概率 $\pi_{ij}$ 很难求得，因此方差的估计也非常困难。</p>
<ul>
<li>当样本量 $n=2$ 时，πPS抽样的实施和估计较为可行。</li>
<li>当 $n&gt;2$ 时，严格的πPS抽样相当复杂。实际应用中，通常通过分层，在每层中再进行严格的样本量为2的πPS抽样。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="特例：单元规模相等时">特例：单元规模相等时</h3>
<p>$$<br>
Z_i = \frac{M_i}{M_0} = \frac{1}{N}, \quad \pi_i = \frac{n}{N}, \quad \pi_{ij} = \frac{n}{N} \cdot \frac{n-1}{N-1}<br>
$$<br>
此时，<strong>不放回简单随机抽样</strong>是πPS抽样的一个特例。</p>
<hr>
<h3 id="估计量">估计量</h3>
<h4 id="霍维茨－汤普森（Horvitz－Thompson）估计量">霍维茨－汤普森（Horvitz－Thompson）估计量</h4>
<p>霍维茨－汤普森估计量立足于包含概率，也称为<strong>π估计量</strong>。</p>
<ol>
<li>
<p><strong>总量 $Y$ 的HT估计</strong>：<br>
$$<br>
\hat{Y}<em>{HT} = \sum</em>{i=1}^n \frac{y_i}{\pi_i}<br>
$$</p>
</li>
<li>
<p><strong>期望</strong>：<br>
$$<br>
E(\hat{Y}_{HT}) = Y<br>
$$</p>
</li>
<li>
<p><strong>方差</strong>：<br>
$$<br>
V(\hat{Y}<em>{HT}) = \sum</em>{i=1}^N \sum_{j=1}^N \left( \frac{\pi_{ij}}{\pi_i \pi_j} - 1 \right) Y_i Y_j<br>
$$</p>
</li>
<li>
<p><strong>方差估计</strong>：<br>
$$<br>
v(\hat{Y}<em>{HT}) = \sum</em>{i=1}^n \sum_{j=1}^n \left( \frac{1}{\pi_i \pi_j} - \frac{1}{\pi_{ij}} \right) y_i y_j<br>
$$</p>
</li>
</ol>
<hr>
<h3 id="【证明】">【证明】</h3>
<p>定义示性函数：<br>
$$<br>
I_i =<br>
\begin{cases}<br>
1 &amp; i \in S \<br>
0 &amp; i \notin S<br>
\end{cases},<br>
\quad i = 1, 2, \cdots, N<br>
$$</p>
<p>Horvitz-Thompson估计量：<br>
$$<br>
\hat{Y}<em>{HT} = \sum</em>{i=1}^n \frac{y_i}{\pi_i} = \sum_{i=1}^N \frac{I_i Y_i}{\pi_i}<br>
$$</p>
<p>由此得：</p>
<ul>
<li>$E(I_i) = \pi_i$</li>
<li>$\text{Cov}(I_i, I_j) = \pi_{ij} - \pi_i \pi_j$，注意 $\pi_{ii} = \pi_i$</li>
</ul>
<p>期望的计算：<br>
$$<br>
E(\hat{Y}<em>{HT}) = E \left( \sum</em>{i=1}^N \frac{I_i Y_i}{\pi_i} \right)<br>
= \sum_{i=1}^N \frac{E(I_i) Y_i}{\pi_i}<br>
= \sum_{i=1}^N Y_i<br>
= Y<br>
$$</p>
<h3 id="方差计算">方差计算</h3>
<p>Horvitz-Thompson估计量的方差为：<br>
$$<br>
V(\hat{Y}<em>{HT}) = \text{Cov} \left( \sum</em>{i=1}^N \frac{I_i Y_i}{\pi_i}, \sum_{i=1}^N \frac{I_i Y_i}{\pi_i} \right)<br>
= \sum_{i=1}^N \sum_{j=1}^N \frac{Y_i Y_j}{\pi_i \pi_j} \text{Cov}(I_i, I_j)<br>
$$</p>
<p>由协方差公式 $\text{Cov}(I_i, I_j) = \pi_{ij} - \pi_i \pi_j$，得：<br>
$$<br>
= \sum_{i=1}^N \sum_{j=1}^N \frac{Y_i Y_j}{\pi_i \pi_j} (\pi_{ij} - \pi_i \pi_j)<br>
$$</p>
<p>$$<br>
= \sum_{i=1}^N \sum_{j=1}^N \left( \frac{\pi_{ij}}{\pi_i \pi_j} - 1 \right) Y_i Y_j<br>
$$</p>
<h3 id="方差估计的期望">方差估计的期望</h3>
<p>$$<br>
E\left[v(\hat{Y}<em>{HT})\right] = E\left[\sum</em>{i=1}^n \sum_{j=1}^n \left( \frac{1}{\pi_i \pi_j} - \frac{1}{\pi_{ij}} \right) y_i y_j\right]<br>
$$</p>
<p>$$<br>
= E\left[\sum_{i=1}^N \sum_{j=1}^N \left( \frac{1}{\pi_i \pi_j} - \frac{1}{\pi_{ij}} \right) I_i I_j Y_i Y_j\right]<br>
$$</p>
<p>根据期望的性质：<br>
$$<br>
= \sum_{i=1}^N \sum_{j=1}^N \left( \frac{1}{\pi_i \pi_j} - \frac{1}{\pi_{ij}} \right) \pi_{ij} Y_i Y_j<br>
$$</p>
<p>$$<br>
= \sum_{i=1}^N \sum_{j=1}^N \left( \frac{\pi_{ij}}{\pi_i \pi_j} - 1 \right) Y_i Y_j<br>
$$</p>
<p>$$<br>
= V(\hat{Y}_{HT})<br>
$$</p>
<h2 id="比率估计和回归估计">比率估计和回归估计</h2>
<h3 id="定义比较">定义比较</h3>
<p><strong>比率估计</strong>和<strong>回归估计</strong>都是利用辅助变量的信息改进估计的方法，二者都是非线性估计。</p>
<h4 id="比率估计">比率估计</h4>
<ul>
<li>比率是两个变量的比值。</li>
<li>设目标变量为 $Y$，另一个与 $Y$ 有关的辅助变量为 $X$，对样本中的每一个单元获得 $Y$ 和 $X$ 的调查值 $Y_i$ 和 $X_i$，然后计算样本比率，作为总体比率的估计。如每百人拥有病床数。</li>
<li><strong>比率估计不是抽样方式，而是估计方法。</strong></li>
</ul>
<h4 id="回归估计">回归估计</h4>
<ul>
<li>利用目标变量与辅助变量的线性回归关系来提高估计效果的方法。</li>
<li>比率估计是假定回归线通过原点，但如果𝑌和𝑋之间存在近似的线性关系，但这(直)线并不通过𝑌和𝑋构成的平面坐标的原点，也就是所谓截距不等于0，那么这时利用比率估计显然不合适，可以构造𝑌对𝑋的线性回归关系进行估计。</li>
</ul>
<h3 id="应用条件">应用条件</h3>
<ol>
<li>目标变量与辅助变量存在相关关系；</li>
<li>有相应辅助变量的总体均值或总值；</li>
<li>样本量较大。</li>
</ol>
<hr>
<h2 id="比率估计与估计量">比率估计与估计量</h2>
<h3 id="简单随机抽样（SRS）下的比率估计">简单随机抽样（SRS）下的比率估计</h3>
<h4 id="总体比率">总体比率</h4>
<p>$$<br>
R = \frac{\bar{Y}}{\bar{X}} = \frac{\sum_{i=1}^N Y_i}{\sum_{i=1}^N X_i}<br>
$$</p>
<h4 id="估计量-2">估计量</h4>
<p>$$<br>
\hat{R} = \frac{\bar{y}}{\bar{x}} = \frac{\sum_{i=1}^n y_i}{\sum_{i=1}^n x_i}<br>
$$</p>
<h4 id="总体均值的估计">总体均值的估计</h4>
<p>$$<br>
\hat{\bar{Y}<em>R} = \frac{\bar{y}}{\bar{x}} \bar{X} = \frac{\sum</em>{i=1}^n y_i}{\sum_{i=1}^n x_i} \bar{X}<br>
$$</p>
<h4 id="总体总量的估计">总体总量的估计</h4>
<p>$$<br>
\hat{Y}<em>R = \frac{\bar{y}}{\bar{x}} X = \frac{\sum</em>{i=1}^n y_i}{\sum_{i=1}^n x_i} X = N \hat{\bar{Y}_R}<br>
$$</p>
<h4 id="偏倚与渐近无偏性">偏倚与渐近无偏性</h4>
<p>对于简单随机抽样，比率估计 $\hat{R}$、$\bar{y}_R$ 和 $\hat{Y}_R$ 是有偏的，但当样本量 $n$ 较大时，它们是渐近无偏的：<br>
$$<br>
E(\hat{R}) \approx R, \quad E(\bar{y}_R) \approx \bar{Y}, \quad E(\hat{Y}_R) \approx Y<br>
$$</p>
<h4 id="方差">方差</h4>
<p>$$<br>
V(\hat{R}) \approx \frac{1-f}{n \bar{X}^2} \left( S_Y^2 + R^2 S_X^2 - 2R S_{XY} \right)<br>
$$<br>
$$<br>
V(\hat{\bar{Y}<em>R} ) \approx \frac{1-f}{n} \left( S_Y^2 + R^2 S_X^2 - 2R S</em>{XY} \right)<br>
$$<br>
$$<br>
V(\hat{Y}<em>R) \approx \frac{N^2 (1-f)}{n} \left( S_Y^2 + R^2 S_X^2 - 2R S</em>{XY} \right)<br>
$$</p>
<h4 id="方差估计">方差估计</h4>
<p>$$<br>
v(\hat{R}) \approx \frac{1-f}{n \bar{X}^2} \left( s_y^2 + R^2 s_x^2 - 2R s_{xy} \right)<br>
$$<br>
$$<br>
v(\hat{\bar{Y}<em>R} ) \approx \frac{1-f}{n} \left( s_y^2 + R^2 s_x^2 - 2R s</em>{xy} \right)<br>
$$<br>
$$<br>
v(\hat{Y}<em>R) \approx \frac{N^2 (1-f)}{n} \left( s_y^2 + R^2 s_x^2 - 2R s</em>{xy} \right)<br>
$$</p>
<hr>
<h2 id="分层抽样（ST）下的比率估计">分层抽样（ST）下的比率估计</h2>
<h3 id="分别比率估计">分别比率估计</h3>
<p>分别计算各层比率：<br>
$$<br>
r_1 = \frac{\sum y_1}{\sum x_1}, \quad r_2 = \frac{\sum y_2}{\sum x_2}, \dots, \quad r_L = \frac{\sum y_L}{\sum x_L}<br>
$$</p>
<p>然后合成总体估计：<br>
$$<br>
\bar{y}<em>{Rs} = \sum</em>{h=1}^L W_h \bar{y}<em>{Rh} = \sum</em>{h=1}^L W_h \frac{\bar{y}<em>h}{\bar{x}<em>h} \bar{X}<em>h<br>
$$<br>
$$<br>
\hat{Y}</em>{Rs} = N \bar{y}</em>{Rs} = \sum</em>{h=1}^L \frac{\bar{y}<em>h}{\bar{x}<em>h} X_h = \sum</em>{h=1}^L \hat{Y}</em>{Rh}<br>
$$</p>
<p>当各层样本量 $n_h$ 较大时：<br>
$$<br>
E(\bar{y}_{Rs}) \approx \bar{Y}<br>
$$</p>
<h4 id="估计量的方差">估计量的方差</h4>
<p>分别比率估计的方差公式：<br>
$$<br>
V(\bar{y}<em>{Rs}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_h^2 S_{xh}^2 - 2R_h \rho_h S_{yh} S_{xh}\right)<br>
$$<br>
$$<br>
V(\hat{Y}<em>{Rs}) \approx \sum</em>{h=1}^L \frac{N_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_h^2 S_{xh}^2 - 2R_h \rho_h S_{yh} S_{xh}\right)<br>
$$</p>
<hr>
<h3 id="联合比率估计">联合比率估计</h3>
<ol>
<li>按分层抽样估计方法计算总体的样本均值 $\bar{y}<em>{st}$ 和 $\bar{x}</em>{st}$；</li>
<li>再采用比率估计：<br>
$$<br>
\bar{y}<em>{Rc} = \frac{\bar{y}</em>{st}}{\bar{x}<em>{st}} \bar{X}<br>
$$<br>
$$<br>
\hat{Y}</em>{Rc} = \frac{\bar{y}<em>{st}}{\bar{x}</em>{st}} X<br>
$$</li>
</ol>
<p>当总样本量 $n$ 较大时：<br>
$$<br>
E(\bar{y}_{Rc}) \approx \bar{Y}<br>
$$</p>
<h4 id="估计量的方差-2">估计量的方差</h4>
<p>联合比率估计的方差公式：<br>
$$<br>
V(\bar{y}<em>{Rc}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_c^2 S_{xh}^2 - 2R_c \rho_h S_{yh} S_{xh}\right)<br>
$$<br>
$$<br>
V(\hat{Y}<em>{Rc}) \approx \sum</em>{h=1}^L \frac{N_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_c^2 S_{xh}^2 - 2R_c \rho_h S_{yh} S_{xh}\right)<br>
$$</p>
<hr>
<h3 id="两者效率比较">两者效率比较</h3>
<h4 id="分别比率估计-2">分别比率估计</h4>
<p>$$<br>
V(\bar{y}<em>{Rs}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_h^2 S_{xh}^2 - 2R_h \rho_h S_{yh} S_{xh}\right)<br>
$$</p>
<h4 id="联合比率估计-2">联合比率估计</h4>
<p>$$<br>
V(\bar{y}<em>{Rc}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_c^2 S_{xh}^2 - 2R_c \rho_h S_{yh} S_{xh}\right)<br>
$$</p>
<hr>
<h3 id="使用建议">使用建议</h3>
<ol>
<li><strong>样本量较大</strong>：分别比率估计效果更好；</li>
<li><strong>样本量较小</strong>：联合比率估计效果更好；</li>
<li><strong>各层比率 $r_h$ 相似</strong>：联合比率估计更适合；</li>
<li><strong>各层比率 $r_h$ 差异显著且样本量较大</strong>：分别比率估计更合适。</li>
</ol>
<h1>SRS下的回归估计</h1>
<h2 id="总体均值的回归估计量定义">总体均值的回归估计量定义</h2>
<p>$$<br>
\bar{y}_{lr} = \bar{y} + \beta (\bar{X} - \bar{x}) = \bar{y} - \beta (\bar{x} - \bar{X})<br>
$$</p>
<ul>
<li>$\beta = 0$：为简单估计量；</li>
<li>$\beta = R$：为比率估计；</li>
<li>$\beta = 1$：为差值估计。</li>
</ul>
<p>因此，简单估计量与比率估计量都是回归估计量的特例。</p>
<hr>
<h2 id="总量估计">总量估计</h2>
<p>$$<br>
\hat{Y}<em>{lr} = N \bar{y}</em>{lr}<br>
$$</p>
<p>对于简单随机抽样回归估计量，作为 Y̅ 和 $Y$ 的回归估计：<br>
$$<br>
E(\bar{y}<em>{lr}) = \bar{Y}<br>
$$<br>
$$<br>
E(\hat{Y}</em>{lr}) = E(N \bar{y}_{lr}) = N \bar{Y} = Y<br>
$$</p>
<hr>
<h2 id="估计量的方差-3">估计量的方差</h2>
<p>$$<br>
V(\bar{y}<em>{lr}) = \frac{(1 - f)}{n} \left(S_y^2 + \beta^2 S_x^2 - 2\beta S</em>{xy}\right)<br>
$$<br>
$$<br>
V(\hat{Y}<em>{lr}) = \frac{N^2 (1 - f)}{n} \left(S_y^2 + \beta^2 S_x^2 - 2\beta S</em>{xy}\right)<br>
$$</p>
<p><strong>方差的估计式：</strong><br>
$$<br>
v(\bar{y}<em>{lr}) = \frac{(1 - f)}{n} \left(s_y^2 + \beta^2 s_x^2 - 2\beta s</em>{xy}\right)<br>
$$<br>
$$<br>
v(\hat{Y}<em>{lr}) = \frac{N^2 (1 - f)}{n} \left(s_y^2 + \beta^2 s_x^2 - 2\beta s</em>{xy}\right)<br>
$$</p>
<hr>
<h2 id="回归系数未知时的估计">回归系数未知时的估计</h2>
<p>此时需要用样本回归系数（最小二乘估计）来代替总体回归系数：<br>
$$<br>
\hat{\beta} = b = \frac{s_{xy}}{s_x^2} = \frac{\sum_{i=1}^n (y_i - \bar{y})(x_i - \bar{x})}{\sum_{i=1}^n (x_i - \bar{x})^2}<br>
$$</p>
<h3 id="回归估计量的性质">回归估计量的性质</h3>
<ol>
<li>
<p><strong>性质1</strong>：简单随机抽样回归估计量 $\bar{y}_{lr} = \bar{y} + b (\bar{X} - \bar{x})$ 是有偏的，但当样本量充分大时，估计量的偏倚趋于零，因此回归估计量是 <strong>渐近无偏的</strong>。</p>
</li>
<li>
<p><strong>性质2</strong>：当样本量较大时，$\bar{y}<em>{lr}$ 的均方误差约等于方差：<br>
$$<br>
MSE(\bar{y}</em>{lr}) \approx V(\bar{y}_{lr}) \approx \frac{(1 - f)}{n} S_y^2 (1 - \rho^2)<br>
$$</p>
<p><strong>均方误差的估计：</strong><br>
$$<br>
v(\bar{y}<em>{lr}) = \frac{(1 - f)}{n} s_e^2<br>
$$<br>
其中，$s_e^2$ 为样本的残差方差：<br>
$$<br>
s_e^2 = \frac{1}{n - 2} \sum</em>{i=1}^n \left[(y_i - \bar{y}) - b (x_i - \bar{x})\right]^2 = \frac{n - 1}{n - 2} \left(s_y^2 - b^2 s_x^2\right)<br>
$$</p>
</li>
</ol>
<hr>
<h1>ST下回归估计</h1>
<p>当各层样本量较小时，通常采用 <strong>联合回归估计</strong>；当各层样本量较大时，可采用 <strong>分别回归估计</strong>。</p>
<p>两者的区别：</p>
<ul>
<li><strong>分别回归估计</strong>：先“回归”再“加权”。</li>
<li><strong>联合回归估计</strong>：先“加权”再“回归”。</li>
</ul>
<hr>
<h2 id="分别回归估计">分别回归估计</h2>
<h3 id="均值估计-2">均值估计</h3>
<p>$$<br>
\bar{y}<em>{lrs} = \sum</em>{h=1}^L W_h \bar{y}<em>{lrh} = \sum</em>{h=1}^L W_h \left[\bar{y}_h + \beta_h (\bar{X}_h - \bar{x}_h)\right]<br>
$$</p>
<h3 id="总量估计-2">总量估计</h3>
<p>$$<br>
\hat{Y}<em>{lrs} = \sum</em>{h=1}^L N_h \bar{y}<em>{lrh} = \sum</em>{h=1}^L N_h \left[\bar{y}_h + \beta_h (\bar{X}_h - \bar{x}_h)\right]<br>
$$</p>
<h3 id="方差估计-2">方差估计</h3>
<p>当各层的回归系数 $\beta_{0h}$ 为事先给定的常数时，估计量无偏，其方差为：<br>
$$<br>
V(\bar{y}<em>{lrs}) = \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + \beta_{0h}^2 S_{xh}^2 - 2\beta_{0h} S_{xyh}\right)<br>
$$</p>
<h4 id="最小方差条件">最小方差条件</h4>
<p>当 $\beta_{0h} = B_h = \frac{S_{xyh}}{S_{xh}^2}$ 时，方差达到最小值：<br>
$$<br>
V_{\text{min}}(\bar{y}<em>{lrs}) = \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} S_{yh}^2 (1 - \rho_h^2)<br>
$$</p>
<h4 id="样本回归系数">样本回归系数</h4>
<p>如果 $\beta_h$ 未知，用样本回归系数 $b_h$ 估计：<br>
$$<br>
\hat{\beta}<em>h = b_h = \frac{\sum</em>{i=1}^{n_h} (y_{hi} - \bar{y}<em>h)(x</em>{hi} - \bar{x}<em>h)}{\sum</em>{i=1}^{n_h} (x_{hi} - \bar{x}<em>h)^2}<br>
$$<br>
此时估计量有偏，但当每层样本量 $n_h$ 较大时，偏倚可以忽略，方差近似为：<br>
$$<br>
V(\bar{y}</em>{lrs}) \approx \sum_{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} S_{yh}^2 (1 - \rho_h^2)<br>
$$<br>
$$<br>
v(\bar{y}<em>{lrs}) = \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} s_{eh}^2<br>
$$</p>
<p><strong>式中：</strong><br>
$$<br>
s_{eh}^2 = \frac{1}{n_h - 2} \sum_{i=1}^{n_h} \left[(y_{hi} - \bar{y}<em>h) - b_h (x</em>{hi} - \bar{x}_h)\right]^2<br>
$$</p>
<hr>
<h2 id="联合回归估计">联合回归估计</h2>
<h3 id="均值估计-3">均值估计</h3>
<p>$$<br>
\bar{y}<em>{lrc} = \bar{y}</em>{st} + \beta (\bar{X} - \bar{x}_{st})<br>
$$</p>
<h3 id="总量估计-3">总量估计</h3>
<p>$$<br>
\hat{Y}<em>{lrc} = N \bar{y}</em>{lrc} = \hat{Y}<em>{st} + \beta (X - \hat{X}</em>{st})<br>
$$</p>
<h3 id="样本回归系数-2">样本回归系数</h3>
<p>当回归系数未知时，用样本回归系数 $b_c$ 代替：<br>
$$<br>
b_c = \frac{\sum_{h=1}^L \frac{W_h^2 (1 - f_h) s_{xyh}}{n_h}}{\sum_{h=1}^L \frac{W_h^2 (1 - f_h) s_{xh}^2}{n_h}}<br>
$$</p>
<h3 id="方差估计-3">方差估计</h3>
<p>$$<br>
V(\bar{y}<em>{lrc}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + B_c^2 S_{xh}^2 - 2B_c S_{xyh}\right)<br>
$$</p>
<p><strong>方差的样本估计：</strong><br>
$$<br>
v(\bar{y}<em>{lrc}) = \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(s_{yh}^2 + b_c^2 s_{xh}^2 - 2b_c s_{xyh}\right)<br>
$$</p>
<hr>
<h2 id="两者效率比较-2">两者效率比较</h2>
<ol>
<li>
<p><strong>分别回归估计</strong> 的方差：<br>
$$<br>
V(\bar{y}<em>{lrs}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_h^2 S_{xh}^2 - 2R_h \rho_h S_{yh} S_{xh}\right)<br>
$$</p>
</li>
<li>
<p><strong>联合回归估计</strong> 的方差：<br>
$$<br>
V(\bar{y}<em>{lrc}) \approx \sum</em>{h=1}^L \frac{W_h^2 (1 - f_h)}{n_h} \left(S_{yh}^2 + R_c^2 S_{xh}^2 - 2R_c \rho_h S_{yh} S_{xh}\right)<br>
$$</p>
</li>
</ol>
<p><strong>比较：</strong></p>
<ul>
<li>各层样本量大时，分别回归估计更优；</li>
<li>总样本量较大但各层样本量较小时，联合回归估计更优；</li>
<li>当各层回归系数相似时，联合回归估计更优；</li>
<li>当各层回归系数差异较大且样本量较大时，分别回归估计更优。</li>
</ul>
<hr>
<h2 id="回归估计与比率估计比较">回归估计与比率估计比较</h2>
<p>对于简单随机抽样：</p>
<ol>
<li>简单估计量的方差：<br>
$$<br>
V(\bar{y}) = \frac{1 - f}{n} S_y^2<br>
$$</li>
<li>比率估计量的方差：<br>
$$<br>
V(\bar{y}_R) \approx \frac{1 - f}{n} \left(S_y^2 + R^2 S_x^2 - 2R \rho S_x S_y\right)<br>
$$</li>
</ol>
<p><strong>比率估计优于简单估计的条件：</strong><br>
$$<br>
R^2 S_x^2 - 2R \rho S_x S_y \leq \rho^2 S_y^2<br>
$$</p>
<p>当 $B = R$ 时，回归估计与比率估计效率相同；否则，回归估计优于比率估计。</p>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>抽样技术大总结</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://gunjo-radio-ii.cc/posts/97773c8f.html">https://gunjo-radio-ii.cc/posts/97773c8f.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>yumenomajo🧙‍</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2024-12-13</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2025-02-01</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%8A%BD%E6%A0%B7%E6%8A%80%E6%9C%AF/"><div class="tags-punctuation"><svg class="faa-tada icon" style="height:1.1em;width:1.1em;fill:currentColor;position:relative;top:2px;margin-right:3px" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg></div>抽样技术</a><a class="post-meta__tags" href="/tags/%E7%BB%9F%E8%AE%A1/"><div class="tags-punctuation"><svg class="faa-tada icon" style="height:1.1em;width:1.1em;fill:currentColor;position:relative;top:2px;margin-right:3px" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg></div>统计</a></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/5f73ddd1.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://api.illlights.com/v1/img?rand=${Math.random()}" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">markdown规范自用</div></div></a></div><div class="next-post pull-right"><a href="/posts/5c4554ba.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/cover.jpg" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">12.11小记</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:bold">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">简单随机抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E4%B8%8E%E7%89%B9%E7%82%B9"><span class="toc-text">一、抽样方法与特点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%EF%BC%9A"><span class="toc-text">定义：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%BC%B0%E8%AE%A1%E9%87%8F%E4%B8%8E%E4%BC%B0%E8%AE%A1%E9%87%8F%E6%80%A7%E8%B4%A8"><span class="toc-text">二、估计量与估计量性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E4%B8%AA%E5%B8%B8%E7%94%A8%E4%BC%B0%E8%AE%A1%E9%87%8F%EF%BC%9A"><span class="toc-text">三个常用估计量：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">均值估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">总量估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">比例估计：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%BE%E5%9B%9E%E7%AE%80%E5%8D%95%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7%E4%B8%AD%E7%9A%84%E4%BC%B0%E8%AE%A1%E9%87%8F%E5%8F%8A%E5%85%B6%E6%80%A7%E8%B4%A8"><span class="toc-text">放回简单随机抽样中的估计量及其性质</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A-2"><span class="toc-text">均值估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1%EF%BC%9A-2"><span class="toc-text">总量估计：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%BE%E5%9B%9E%E6%8A%BD%E6%A0%B7%E4%B8%8E%E4%B8%8D%E6%94%BE%E5%9B%9E%E6%8A%BD%E6%A0%B7%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">放回抽样与不放回抽样的比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%A0%B7%E6%9C%AC%E9%87%8F%E7%9A%84%E7%A1%AE%E5%AE%9A%EF%BC%88%E5%B9%BF%E4%B9%89%E8%AE%A8%E8%AE%BA%EF%BC%89"><span class="toc-text">三、样本量的确定（广义讨论）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%B4%B9%E7%94%A8%EF%BC%9A"><span class="toc-text">1. 费用：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BC%B0%E8%AE%A1%E7%B2%BE%E5%BA%A6%EF%BC%9A"><span class="toc-text">2.估计精度：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#A-%E7%B2%BE%E5%BA%A6%E8%A6%81%E6%B1%82%E4%B8%8E%E6%A0%B7%E6%9C%AC%E9%87%8F%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%9A"><span class="toc-text">A. 精度要求与样本量的关系：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#B-%E7%B2%BE%E5%BA%A6-%E8%AF%AF%E5%B7%AE%E5%92%8C%E7%BD%AE%E4%BF%A1%E6%B0%B4%E5%B9%B3%E8%AE%A8%E8%AE%BA%EF%BC%9A"><span class="toc-text">B. 精度-误差和置信水平讨论：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE%E8%A1%A8%E7%A4%BA%EF%BC%9A"><span class="toc-text">绝对误差表示：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%AF%B9%E8%AF%AF%E5%B7%AE%E8%A1%A8%E7%A4%BA%EF%BC%9A"><span class="toc-text">相对误差表示：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#C-%E4%BC%B0%E8%AE%A1%E9%87%8F%E6%96%B9%E5%B7%AE%E4%B8%8E%E7%B2%BE%E5%BA%A6%EF%BC%88%E8%AF%AF%E5%B7%AE%E5%92%8C%E7%BD%AE%E4%BF%A1%E6%B0%B4%E5%B9%B3%EF%BC%89%E5%85%B3%E7%B3%BB"><span class="toc-text">C. 估计量方差与精度（误差和置信水平）关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%8C-%E6%B1%82%E5%BE%97%E5%90%88%E9%80%82%E6%A0%B7%E6%9C%AC%E9%87%8F"><span class="toc-text">3， 求得合适样本量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%A0%B7%E6%9C%AC%E9%87%8F%E7%9A%84%E7%A1%AE%E5%AE%9A%EF%BC%88%E7%AE%80%E5%8D%95%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7%EF%BC%89"><span class="toc-text">四、样本量的确定（简单随机抽样）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A-3"><span class="toc-text">均值估计：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A-2"><span class="toc-text">比例估计：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-text"></span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">分层抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E4%B8%8E%E7%89%B9%E7%82%B9-2"><span class="toc-text">一、抽样方法与特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%BC%B0%E8%AE%A1%E9%87%8F%E4%B8%8E%E4%BC%B0%E8%AE%A1%E9%87%8F%E6%80%A7%E8%B4%A8-2"><span class="toc-text">二、估计量与估计量性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E4%B8%AA%E5%B8%B8%E7%94%A8%E4%BC%B0%E8%AE%A1%E9%87%8F%EF%BC%9A-2"><span class="toc-text">三个常用估计量：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A-4"><span class="toc-text">均值估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1%EF%BC%9A-3"><span class="toc-text">总量估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A-3"><span class="toc-text">比例估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%95%B0%E9%87%8F%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">特征数量估计：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%BA%94%E6%80%A7%E8%B4%A8%EF%BC%88%E6%9C%9F%E6%9C%9B%E5%92%8C%E6%96%B9%E5%B7%AE%EF%BC%89%EF%BC%9A"><span class="toc-text">对应性质（期望和方差）：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A-5"><span class="toc-text">均值估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1%EF%BC%9A-4"><span class="toc-text">总量估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A-4"><span class="toc-text">比例估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%95%B0%E9%87%8F%E4%BC%B0%E8%AE%A1"><span class="toc-text">特征数量估计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81-%E6%A0%B7%E6%9C%AC%E9%87%8F%E5%9C%A8%E5%90%84%E5%B1%82%E7%9A%84%E5%88%86%E9%85%8D"><span class="toc-text">三、 样本量在各层的分配</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%AF%94%E4%BE%8B%E5%88%86%E9%85%8D"><span class="toc-text">1. 比例分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%9C%80%E4%BC%98%E5%88%86%E9%85%8D"><span class="toc-text">2. 最优分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A5%88%E6%9B%BC%E5%88%86%E9%85%8D"><span class="toc-text">3. 奈曼分配</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%80%BB%E6%A0%B7%E6%9C%AC%E9%87%8F%E7%9A%84%E7%A1%AE%E5%AE%9A-%E5%85%B3%E9%94%AE%E5%9C%A8%E4%BA%8E%E7%90%86%E8%A7%A3n%E5%92%8CV%E7%9A%84%E8%B4%9F%E7%9B%B8%E5%85%B3%E5%85%B3%E7%B3%BB"><span class="toc-text">四、总样本量的确定[关键在于理解n和V的负相关关系]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7%E6%A0%B7%E6%9C%AC%E9%87%8F%E7%A1%AE%E5%AE%9A%E4%B8%80%E8%88%AC%E5%85%AC%E5%BC%8F"><span class="toc-text">1. 分层抽样样本量确定一般公式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%B8%8D%E5%90%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E5%90%88"><span class="toc-text">2. 不同应用场合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%88%92%E5%88%86%E5%B1%82%E9%97%AE%E9%A2%98"><span class="toc-text">五、划分层问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%B1%82%E7%9A%84%E7%95%8C%E9%99%90"><span class="toc-text">1. 层的界限</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%B1%82%E6%95%B0%E7%9A%84%E7%A1%AE%E5%AE%9A"><span class="toc-text">2. 层数的确定</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%85%B6%E4%BB%96%E5%88%86%E5%B1%82%E6%8A%80%E6%9C%AF"><span class="toc-text">五、其他分层技术</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%9B%AE%E5%BD%95%E6%8A%BD%E6%A0%B7"><span class="toc-text">1. 目录抽样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%82-%E4%BA%8B%E5%90%8E%E5%88%86%E5%B1%82"><span class="toc-text">2。 事后分层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#-2"><span class="toc-text"></span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">整群抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E4%B8%8E%E7%89%B9%E7%82%B9-3"><span class="toc-text">一、抽样方法与特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%BC%B0%E8%AE%A1%E9%87%8F%E4%B8%8E%E4%BC%B0%E8%AE%A1%E9%87%8F%E6%80%A7%E8%B4%A8-3"><span class="toc-text">二、估计量与估计量性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F%EF%BC%9A"><span class="toc-text">估计量：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E7%9B%B8%E7%AD%89%E6%97%B6%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">群规模相等时均值估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E7%9B%B8%E7%AD%89%E6%97%B6%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">群规模相等时比例估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E4%B8%8D%E7%AD%89%E6%97%B6%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">群规模不等时均值估计：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AD%89%E6%A6%82%E6%8A%BD%E6%A0%B7%E7%AE%80%E5%8D%95%E4%BC%B0%E8%AE%A1"><span class="toc-text">等概抽样简单估计</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AD%89%E6%A6%82%E6%8A%BD%E6%A0%B7%E5%8A%A0%E6%9D%83%E4%BC%B0%E8%AE%A1"><span class="toc-text">等概抽样加权估计</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AD%89%E6%A6%82%E6%8A%BD%E6%A0%B7%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1"><span class="toc-text">等概抽样比例估计</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E4%B8%8D%E7%AD%89%E6%97%B6%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">群规模不等时比例估计：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%BA%94%E6%80%A7%E8%B4%A8%EF%BC%88%E6%9C%9F%E6%9C%9B%E5%92%8C%E6%96%B9%E5%B7%AE%EF%BC%89%EF%BC%9A-2"><span class="toc-text">对应性质（期望和方差）：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E7%9B%B8%E7%AD%89%E6%97%B6%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1%EF%BC%9A-2"><span class="toc-text">群规模相等时均值估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E7%9B%B8%E7%AD%89%E6%97%B6%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A-2"><span class="toc-text">群规模相等时比例估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%89%E6%A6%82%E6%8A%BD%E6%A0%B7%E7%AE%80%E5%8D%95%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">等概抽样简单估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%89%E6%A6%82%E6%8A%BD%E6%A0%B7%E5%8A%A0%E6%9D%83%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">等概抽样加权估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%89%E6%A6%82%E6%8A%BD%E6%A0%B7%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">等概抽样比例估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E8%A7%84%E6%A8%A1%E4%B8%8D%E7%AD%89%E6%97%B6%E6%AF%94%E4%BE%8B%E4%BC%B0%E8%AE%A1%EF%BC%9A-2"><span class="toc-text">群规模不等时比例估计：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E7%BE%A4%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-text">三、群的划分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8E%9F%E5%88%99%EF%BC%9A"><span class="toc-text">1. 原则：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%B8%80%E4%BA%9B%E6%96%B9%E6%A1%88%EF%BC%9A"><span class="toc-text">2.一些方案：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81-%E7%BE%A4%E7%9A%84%E8%A7%84%E6%A8%A1%EF%BC%88%E7%BE%A4%E7%9A%84%E5%8D%95%E5%85%83%E7%9A%84%E6%95%B0%E9%87%8F%EF%BC%89"><span class="toc-text">四、 群的规模（群的单元的数量）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81-%E6%95%B4%E7%BE%A4%E6%8A%BD%E6%A0%B7%E6%95%88%E7%8E%87%E5%88%86%E6%9E%90"><span class="toc-text">五、 整群抽样效率分析</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">二阶段抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E4%B8%8E%E7%89%B9%E7%82%B9-4"><span class="toc-text">一、抽样方法与特点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0%EF%BC%9A"><span class="toc-text">概述：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%EF%BC%9A-2"><span class="toc-text">定义：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%98%B6%E4%B8%8E%E5%A4%9A%E9%98%B6%E6%8A%BD%E6%A0%B7%E7%9A%84%E4%BC%98%E7%82%B9%EF%BC%9A"><span class="toc-text">二阶与多阶抽样的优点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80"><span class="toc-text">二、理论基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%BC%B0%E8%AE%A1%E9%87%8F%E4%B8%8E%E4%BC%B0%E8%AE%A1%E9%87%8F%E6%80%A7%E8%B4%A8-4"><span class="toc-text">二、估计量与估计量性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9D%E7%BA%A7%E5%8D%95%E5%85%83%E5%A4%A7%E5%B0%8F%E7%9B%B8%E7%AD%89%E6%97%B6%E7%9A%84%E4%BA%8C%E9%98%B6%E6%8A%BD%E6%A0%B7"><span class="toc-text">1. 初级单元大小相等时的二阶抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1"><span class="toc-text">均值估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E5%80%BC%E4%BC%B0%E8%AE%A1"><span class="toc-text">总值估计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%A7%E8%B4%A83%EF%BC%9A%E6%96%B9%E5%B7%AE%E7%9A%84%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1%EF%BC%9A-v-tilde-Y-NM-2-cdot-v-overline-y"><span class="toc-text">性质3：方差的无偏估计：
$$
v(\tilde{Y}) &#x3D; (NM)^2 \cdot v(\overline{y})
$$</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9A"><span class="toc-text">补充：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E5%80%BC%E4%BC%B0%E8%AE%A1-2"><span class="toc-text">总值估计</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%9D%E7%BA%A7%E5%8D%95%E5%85%83%E5%A4%A7%E5%B0%8F%E4%B8%8D%E7%AD%89%E6%97%B6%E7%9A%84%E4%BA%8C%E9%98%B6%E6%8A%BD%E6%A0%B7"><span class="toc-text">2. 初级单元大小不等时的二阶抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E7%AE%80%E5%8D%95%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">(1) 简单估计：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%AF%94%E4%BC%B0%E8%AE%A1%EF%BC%9A"><span class="toc-text">(2) 比估计：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%A0%B7%E6%9C%AC%E9%87%8F%E7%9A%84%E7%A1%AE%E5%AE%9A"><span class="toc-text">三、样本量的确定</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9D%E7%BA%A7%E5%8D%95%E5%85%83%E5%A4%A7%E5%B0%8F%E7%9B%B8%E7%AD%89%E6%97%B6%EF%BC%8C%E6%9C%80%E4%BC%98%E6%A0%B7%E6%9C%AC%E9%87%8F-m-%E4%B8%8E-n-%E7%9A%84%E7%A1%AE%E5%AE%9A%EF%BC%9A"><span class="toc-text">1.初级单元大小相等时，最优样本量 $m$ 与 $n$ 的确定：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">πPS抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%88%AB%E8%AF%B4%E6%98%8E"><span class="toc-text">特别说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E4%BE%8B%EF%BC%9A%E5%8D%95%E5%85%83%E8%A7%84%E6%A8%A1%E7%9B%B8%E7%AD%89%E6%97%B6"><span class="toc-text">特例：单元规模相等时</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F"><span class="toc-text">估计量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%8D%E7%BB%B4%E8%8C%A8%EF%BC%8D%E6%B1%A4%E6%99%AE%E6%A3%AE%EF%BC%88Horvitz%EF%BC%8DThompson%EF%BC%89%E4%BC%B0%E8%AE%A1%E9%87%8F"><span class="toc-text">霍维茨－汤普森（Horvitz－Thompson）估计量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E3%80%90%E8%AF%81%E6%98%8E%E3%80%91"><span class="toc-text">【证明】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E8%AE%A1%E7%AE%97"><span class="toc-text">方差计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%9C%9F%E6%9C%9B"><span class="toc-text">方差估计的期望</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1%E5%92%8C%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1"><span class="toc-text">比率估计和回归估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%AF%94%E8%BE%83"><span class="toc-text">定义比较</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1"><span class="toc-text">比率估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1"><span class="toc-text">回归估计</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E6%9D%A1%E4%BB%B6"><span class="toc-text">应用条件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1%E4%B8%8E%E4%BC%B0%E8%AE%A1%E9%87%8F"><span class="toc-text">比率估计与估计量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7%EF%BC%88SRS%EF%BC%89%E4%B8%8B%E7%9A%84%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1"><span class="toc-text">简单随机抽样（SRS）下的比率估计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E6%AF%94%E7%8E%87"><span class="toc-text">总体比率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F-2"><span class="toc-text">估计量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E5%9D%87%E5%80%BC%E7%9A%84%E4%BC%B0%E8%AE%A1"><span class="toc-text">总体均值的估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E6%80%BB%E9%87%8F%E7%9A%84%E4%BC%B0%E8%AE%A1"><span class="toc-text">总体总量的估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%8F%E5%80%9A%E4%B8%8E%E6%B8%90%E8%BF%91%E6%97%A0%E5%81%8F%E6%80%A7"><span class="toc-text">偏倚与渐近无偏性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE"><span class="toc-text">方差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1"><span class="toc-text">方差估计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7%EF%BC%88ST%EF%BC%89%E4%B8%8B%E7%9A%84%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1"><span class="toc-text">分层抽样（ST）下的比率估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%88%AB%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1"><span class="toc-text">分别比率估计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-text">估计量的方差</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1"><span class="toc-text">联合比率估计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE-2"><span class="toc-text">估计量的方差</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E6%95%88%E7%8E%87%E6%AF%94%E8%BE%83"><span class="toc-text">两者效率比较</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%88%AB%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1-2"><span class="toc-text">分别比率估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1-2"><span class="toc-text">联合比率估计</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%BB%BA%E8%AE%AE"><span class="toc-text">使用建议</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">SRS下的回归估计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E5%9D%87%E5%80%BC%E7%9A%84%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1%E9%87%8F%E5%AE%9A%E4%B9%89"><span class="toc-text">总体均值的回归估计量定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1"><span class="toc-text">总量估计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE-3"><span class="toc-text">估计量的方差</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0%E6%9C%AA%E7%9F%A5%E6%97%B6%E7%9A%84%E4%BC%B0%E8%AE%A1"><span class="toc-text">回归系数未知时的估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-text">回归估计量的性质</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">ST下回归估计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%88%AB%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1"><span class="toc-text">分别回归估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1-2"><span class="toc-text">均值估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1-2"><span class="toc-text">总量估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1-2"><span class="toc-text">方差估计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E6%96%B9%E5%B7%AE%E6%9D%A1%E4%BB%B6"><span class="toc-text">最小方差条件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0"><span class="toc-text">样本回归系数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%94%E5%90%88%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1"><span class="toc-text">联合回归估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1-3"><span class="toc-text">均值估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E9%87%8F%E4%BC%B0%E8%AE%A1-3"><span class="toc-text">总量估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0-2"><span class="toc-text">样本回归系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1-3"><span class="toc-text">方差估计</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E6%95%88%E7%8E%87%E6%AF%94%E8%BE%83-2"><span class="toc-text">两者效率比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E4%BC%B0%E8%AE%A1%E4%B8%8E%E6%AF%94%E7%8E%87%E4%BC%B0%E8%AE%A1%E6%AF%94%E8%BE%83"><span class="toc-text">回归估计与比率估计比较</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-color: transparent;"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">空气动力之诗🌌</p><div class="bg-ad"><div>我们的情人，不过是随便借个名字，用幻想吹出来的肥皂泡。把信拿去吧，你可以使假戏成真。我本来是无病呻吟，漫无目的地吐露爱情……现在这些漂泊不定的鸟儿有地方栖息了你可以从信里看出来——拿去吧！——由于不是出自真心，话就说得格外动听。——拿去吧，就这么办！✨</div><div class="btn-xz-box"><a class="btn-xz" target="_blank" rel="noopener" href="https://www.bilibili.com/bangumi/play/ss5045?spm_id_from=333.337.0.0">点击开启星辰之旅</a></div></div></div><div class="t-t-r"><p class="ft-t t-l-t">猜你想看💡</p><ul class="ft-links"><li><a href="/categories/群青广播/">群青广播</a><a href="/comments/">留点什么</a></li><li><a href="/about/">关于作者</a><a href="/archives/">文章归档</a></li><li><a href="/categories/">文章分类</a><a href="/tags/">文章标签</a></li><li><a target="_blank" rel="noopener" href="https://www.fomal.cc/posts/eec9786.html">建站参考</a><a target="_blank" rel="noopener" href="https://www.acgbox.link">二次元导航</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">推荐友链⌛</p><div class="ft-img-group"><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div></div></div></div><div class="copyright"><span><b>&copy;2024-2025</b></span><span><b>&nbsp;&nbsp;By yumenomajo🧙‍</b></span></div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.3.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Frame-Hexo-blue.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.3.1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Theme-Butterfly-6513df.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站采用多线部署，主线路托管于Vercel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Hosted-Vercel-brightgreen.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本网站源码由Github提供存储仓库"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Source-Github-d021d6.svg" alt=""/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fa fa-paper-plane"></i><span>随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:toggleWinbox();"><i class="fas fa-cog"></i><span>美化设置</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://comments.gunjo-radio-ii.cc/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, {"avatarCDN":"https://weavatar.com/avatar/","avatarForce":false,"defaultGravatar":"mp"}))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://comments.gunjo-radio-ii.cc/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()

</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://comments.gunjo-radio-ii.cc/',
        region: '',
        pageSize: 5,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script async src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="https://cdn1.tianli0.top/gh/nextapps-de/winbox/dist/winbox.bundle.min.js"></script><script async src="//at.alicdn.com/t/c/font_3586335_hsivh70x0fm.js"></script><script async src="//at.alicdn.com/t/c/font_3636804_gr02jmjr3y9.js"></script><script async src="//at.alicdn.com/t/c/font_3612150_kfv55xn3u2g.js"></script><script async src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><script defer src="/js/fomal.js"></script><canvas class="fireworks" mobile="true"></canvas><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/fireworks.min.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax","#bibi","body > title","#app","#tag-echarts","#posts-echart","#categories-echarts"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><a class="magnet_link_more"  href="https://gunjo-radio-ii.cc/categories/" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #e9e9e9;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--text-bg-hover)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/4c44472f.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://api.illlights.com/v1/img?rand=${Math.random(0720)}" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-02-19</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/4c44472f.html&quot;);" href="javascript:void(0);" alt="">视觉小说小记</a><div class="blog-slider__text">粗略记录一下推完的视觉小说。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/4c44472f.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/4649bb35.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://api.illlights.com/v1/img?rand=${Math.random(1)}" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-01-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/4649bb35.html&quot;);" href="javascript:void(0);" alt="">1月20日群青广播更新小记</a><div class="blog-slider__text">记录一下大概一周以来，更新blog做的一些事情。不过主要还是简述更新过程，以后需要更新的时候不至于无从下手。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/4649bb35.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/ea20582a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="\images\post\record0.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-02-19</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/ea20582a.html&quot;);" href="javascript:void(0);" alt="">观剧记录的原初</a><div class="blog-slider__text">观剧记录分类的开端。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/ea20582a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/915faf15.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/post/gunjo.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-12-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/915faf15.html&quot;);" href="javascript:void(0);" alt="">絮絮叨叨的原初</a><div class="blog-slider__text">最初的起点。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/915faf15.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" id="gitcalendarBar" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 320px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/site/census/'|| '/site/census/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("/api?yumenomajo",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'yumenomajo')
    }
  </script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>